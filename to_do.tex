\chapter*{To do}

This is a list of items that must be completed before I consider this book truly complete.

\section*{GitHub readme}

More things about this book that are original that I should call attention to:

\begin{itemize}
    \item Organization of four fundamental isomorphisms for tensors
    \item Above story of diff forms
    \item Using dual spaces to organize the theorem about coordinates of vectors and covectors in a chart (Theorem \ref{ch::manifolds::thm::induced_bases_in_a_chart})
\end{itemize}

\section*{Standardize theorem and proof style}

\begin{itemize}
    \item Statement of hypotheses.
    \begin{itemize}
        \item Possible styles:
        \begin{itemize}
            \item “Let $x$ have $P(x)$, $y$ have $Q(y)$, and $z$ have $R(z)$. Then … $S(x, y, z)$”
            \item “If $x$ has $P(x)$ and $y$ has $Q(y)$ then …”
            \item “$Q(x)$ for all $x$ with $P(x)$”.
            \item “Let $V$ and $W$ be vector spaces. If $\ff:V \rightarrow W$ is a linear function, then …”
            \item “If $\ff:V \rightarrow W$ is a linear function, where $V$ and $W$ are vector spaces, then …”
        \end{itemize}
        \item Definite changes to make:
        \begin{itemize}
            \item For proofs of trivial kernel, always say ``Let $\ff(\vv) = \mathbf{0}$. We need to show $\vv = \mathbf{0}$.'' Make sure the ``We need to show $\vv = \mathbf{0}$'' part is never skipped.
        \end{itemize}
    \end{itemize}
    \item Restatement of hypotheses in proofs
    \begin{itemize}
        \item shorthand: “If $f$ has <most relevant hypothesis from theorem statement>, then blah blah blah…” 
    \end{itemize}
    \item Go through the book and use fullindent command
    \item Which equations should be in the align environment and which should be inline?
    \item Which align environment equations should have ``for all $x$'' inside them, like

    \begin{align*}
        y = f(x) \text{ for all $x$},
    \end{align*}
    
    and which equations should have ``for all $x$'' after the equation, in inline text?
    \item Don't explicitize objects if their explicitization isn't need in the theorem statement. Explicitize them in the proof only as necessary. (e.g. don't state "let $E = \{\ee_1, ..., \ee_n\}$ be a basis of $V$ if it is not necessary to have explicit descriptions of the basis vectors.
    \begin{itemize}
        \item Especially, don't state "let $V$ be a vector space over a field $K$" if $K$ is not needed in the theorem statement. Instead, say "let $K$ be the field under $V$" in the proof.
        \item Add a definition of \textit{under $K$} in the definition of vector space over $K$.
    \end{itemize}
    \item Add more explanatory text in-between definitions, lemmas, theorems where needed.
\end{itemize}


\section*{Logic and proofs}

\begin{itemize}
    \item Superset notation
    \item Need a defn of $S^{\times n}$ since $V^{\times n}$ is used in the tensors section. Note that $S^n$ is alternative notation for $S^{\times n}$
    \item Explanation of how to write a proof of the form $\forall x \spc P(x) \implies (Q(x) \implies R(x))$. For example, $\forall \spc \text{linear functions $\ff$}: \spc \text{$\ff$ is one-to-one} \implies (\text{$\vv_1, ..., \vv_k$ are linearly independent} \implies \text{$\ff(\vv_1), ..., \ff(\vv_k)$ are linearly independent})$.
    \item Maybe put subsection on := vs. = somewhere else. Maybe write a subsection about definitions and theorems and put it there.
    \item Add remark that ``iff'' is shorthand for ``if and only if''.
    \item Proof of $\forall x \in S \spc P(x)$ is formally a proof by cases; we don’t write out the case $x \notin S$ because false hypothesis is obviously true
    \item Remove $-$ as notation for set difference and use $\\$ instead. Add an explanation that $-$ isn’t used because $S - T$ is often defined to mean $\{ s - t | s \in S \text{ and } t \in T\}$
\end{itemize}

\section*{Misc.}

\begin{itemize}
    \item Use $()$ for bases instead of $\{\}$. Make a remark after definition of basis about $()$ vs. $\{\}$ (or maybe this should be obvious given discussion about in logic and proofs chapter)
    \item vector fields should be denoted as $v$, not $\VV$, since a continuous map sending $\pp \mapsto v_\pp$ is a vector field
    \item in ``coordinates of tensors'' section of ``bilinear forms'' chapter, make sure never see expressions like $([\FF]_E)^i_j$, only $([\FF]_E)^i{}_j$
\end{itemize}

\section*{Dot product}

\begin{itemize}
    \item Rewrite dot product section. My ||proj|| doesn’t work. Need to use sproj; projection must be signed, and $n$-dimensional angle approach isn’t actually easier for the beginner to understand; way more inductive proofs with complicated functions are required than I thought.
    \item \textbf{After more thought, have determined that approach in which angle is defined first is too pedagogically confusing. Said approach quickly establishes that the geometric and algebraic formulas for the dot product are equal, but it doesn’t quickly give a sense as to why these formulas must be equal. A beginner using this approach isn’t guaranteed to be strongly motivated to ask “why?”, since it’s clearly established that it is so.}
    \item \textbf{Best approach will be to start in $\R^2$. Define angle between two vectors to be the minimum ratio of arc length to radius on the arc of the circle between the corresponding unit vectors. This implies that $\theta(\vv, \ww) \in [0, \pi]$ for all $\vv, \ww \in \R^2$. Define geometric dot product and appeal to physical work for motivation. Show geometric => algebraic by using linearity. Then show algebraic => geometric by using invariance of dot product under rotation. Then generalize to $\R^n$ by using the algebraic formula.}
    \item Will need to define rotations so that can show algebraic => geometric. So work on rotation section.
\end{itemize}

\subsubsection*{Angle}

Content

\begin{itemize}
    \item Add uses of two types of angles from intro of angle section to within angle section
    \item Minimize mention of modulus. Here’s the path for doing so:
    \begin{itemize}
        \item Lemma. $\theta_s(\vv, \ww) + \tttheta_s(\vv, \ww) = 2\pi$
        \item Lemma. If $t \in [0, 2\pi)$ then $-t \bmod 2\pi = 2\pi - t$
        \item Theorem. $-\theta_s(\vv, \ww) \bmod 2\pi = \tttheta_s(\vv, \ww)$
        \begin{itemize}
            \item Proof. We have $-\theta_s(\vv, \ww) \bmod 2\pi = 2\pi - \theta_s(\vv, \ww)$ by the previous lemma. This is equal to $\tttheta_s(\vv, \ww)$ by the lemma before the previous lemma.
        \end{itemize}
        \item Theorem. $\theta_s(\vv, \ww) = \pm \min(|\theta_s(\vv, \ww)|, |\tttheta_s(\vv, \ww)|) \bmod 2\pi$
    \end{itemize}
    \item Revisit defn of unsigned angle, and show that it is equal to both $|\theta(\vv, \ww)|$ and $|\tttheta(\vv, \ww)|$
        \item Add theorem that $(\vv, \ww)$ is positively oriented iff $|\theta_s(\vv, \ww)| < |\tttheta_s(\vv, \ww)|$ iff $|\theta_s(\vv, \ww)| \leq \pi$
\end{itemize}

Cleanup

\begin{itemize}
    \item Check that $\bmod 2\pi$ appears where it should and doesn't where it shouldn't
    \item Check that correct intervals are used for angles: $[0, 2\pi)$ for signed (not $(-\pi, \pi]$), $[0, \pi]$ for unsigned
    \item Remove all mention of unit speed curves; redid defn of trig so don't need unit speed curves for that anymore
\end{itemize}

\subsubsection*{Rotations}

Three overall goals:

\begin{enumerate}
    \item prove that rotation matrix of CCW rotation by $t$ has a first column of $\cc(t) = (\cos(t), \sin(t))^\top$ and second column of $(-\sin(t), \cos(t))^\top$.
    
    have this theorem properly backed up by a correct notion of angle in which $-\pi/2 \sim 3\pi/2$. we need this for the orientation section; we use $t = \pi/2$ to prove the antisymmetry of ordered bases. 
    \item establish that rotations are isometries, i.e., orthogonal linear functions, and that orthogonal linear functions preserve algebraic dot product. we need this so we can prove algebraic => geometric. this is mostly outlined.
    \item we also need to prove facts about projections for geometric => algebraic, and for the very last part of algebraic => geometric I think. this seems mostly done but go over it to check.
\end{enumerate}

\section*{Orthogonal complements}

ADD A CHAPTER ON ORTHOGONAL COMPLEMENTS.

\begin{itemize}
    \item (Defn). A \textit{hyperplane} is an orthogonal complement of a one-dimensional vector subspace.
    \begin{itemize}
        \item Important to have this so that can talk about visualizing linear equations as hyperplanes.
    \end{itemize}
\end{itemize}

\section*{Systems of linear equations}

\begin{itemize}
    \item Since $\{\text{solns}\} = \ker(\AA) + \{\vv_p\}$ then it must be true that $\rref(\AA | \bb) = (\rref(\AA) | \vv_p)$. Must $\vv_p$ be unique? Yes. (Because there exists a product $\EE$ of elementary matrices such that $\rref(\AA) = \EE \AA$; we have $\vv_p = \EE \bb$. So, might be best to start chapter with solving equations with augmented matrices rather than the theoretical result solns = $\{\text{solns}\} = \ker(\AA) + \{\vv_p\}$, since the former result secretly includes the later.
\end{itemize}

\section*{Tensors}

\begin{itemize}
    \item Current defn of tensor product space (and wedge product space) relies on fact that if $T_1 \sim T_2$ and $S_1 \sim S_2$ then $T_1 + S_1 \sim T_2 + S_2$, which is not too hard to prove. This fact is required to show that the defn is the vector space spanned by elements of the form $\vv_1 \otimes ... \otimes \vv_k$, which is the crucial intuition. Stating this fact obscures the details, so should switch defn to a more informal one, that being the crucial intuition.
    \item Then, add a remark about how one can more formally construct tensor and wedge product spaces by using $F(V \times W)/\sim$ for various $\sim$. See Warner for how to do this, and add a section on quotient vector spaces and $F(V \times W)/\sim$ to the appendix. 
    \item Check if remark on covariance and contravariance is correct in light of the fact that I’ve shown vectors transform with $[\EE]_F$ and covectors transform with its transpose inverse. Aren’t covectors supposed to be the ones that transform with the matrix that isn’t a transpose inverse? Maybe the answer is that the change of basis matrix is considered to be the one containing the vectors from the new basis taken relative to the old basis, i.e. $[\FF]_E$.
    \item Why is it necessary that covector components be indexed oppositely to covectors? Same question goes for vector components and vectors.
    \item After Ricci law: example of changing basis for a purely covariant tensor, a purely contravariant tensor, and a not too complicated mixed tensor
    \item Also, the metric tensor can have its coordinates changed!
    \item Remark: summary of physicist notation. Include the previous remark and the one about the physicist notation regarding the metric tensor.
\end{itemize}

\subsubsection*{Etc.}

\begin{itemize}
    \item choosing an inner product implies a choice of basis, because it implies a choice of orthonormal basis. revisit the remark on when unnatural isomorphism is natural
    \item Replace $V \totimes W := \LLLL(V^* \times W^* \rightarrow K)$ with $V \totimes W := V^{**} \totimes W^{**} = L(V^* \times W^* \rightarrow K)$.
\end{itemize}

\section*{Antisymmetry chapters}

\begin{itemize}
    \item \textbf{Shift framing from “construction of wedge product” to “relationship between wedge and otimes”.}
    \item Pretty sure the following is done but need to double check. 
    \begin{itemize}
        \item (Theorem). There is a natural isomorphism $\Lambda^k(V) \cong \alt(V^{\otimes k}$). That is, every wedge product can be identified with an antisymmetric tensor.
        \begin{itemize}
            \item Lemma. Every antisymmetric tensor $\TT$ is of the form $\TT = \alt(\TT)$.
    
            Proof of lemma. For one containment: we've seen that $\alt(\TT)$ is antisymmetric for all $\TT$. For the other: we've also seen that $\TT$ is alternating then $\TT = \alt(\TT)$.
    
            \item Proof of theorem. $\vv_1 \wedge ... \vv_k \mapsto \alt(\vv_1 \otimes ... \otimes \vv_k)$ defines an isomorphism $\Lambda^k(V) \rightarrow \alt(V^{\otimes k})$ on elementary wedge products. Extend it with seeming-the linearity and seeming-alternatingness of $\wedge$. 
        \end{itemize}
    \end{itemize}

    \item antisymmetric tensors only make sense for $V^{\otimes k}$, not $V_1 \otimes … \otimes V_k$
    \begin{itemize}
        \item search “alternating”
        \item search “antisym”
        \item search $V_1$ with case sensitivity to find places to fix
        \item lots of edits in “as functions” section for this
        \item find places where swap and permutation are mentioned and make them all consistent with this
    \end{itemize}
    \item Add a footnote somewhere that we can't define $\wedge$ before $\det$ because we have to know that volume should be oriented before we get the idea for ``the oriented volume parallelopiped spanned by $\vv_1, ..., \vv_k$''. And to know volume should be oriented, we first have to explore the determinant and orientation.
    \item Make sure this remark is included: $\phi^{\see_1} \wedge ... \wedge \phi^{\see_k}(\vv_1, ..., \vv_k)$ is the volume of the projection of the parallelapiped spanned by $\vv_1, ..., \vv_k$ onto $\spann(\see_{i_1}, …, \see_{i_k})$.
\end{itemize}

\subsubsection{Cross product}

\begin{itemize}
    \item Do \textit{not} introduce the cross product as the vector with a magnitude equal to the area of the spanned parallelogram and direction perpendicular and positively oriented. This is very contrived. Instead, in the linear algebra chapter, after determinants and orientation, introduce the cross product as a natural object that comes out of thinking about the oriented volume of parallelepiped: $(\vv \times \ww)^\top$ is the matrix of the linear function $\uu \mapsto \det(\uu, \vv, \ww)$. That is $(\vv \times \ww) \cdot \uu = \det(\uu, \vv, \ww)$. 
\end{itemize}

\subsubsection{Hodge dual}

\begin{itemize}
    \item Emphasize that Hodge-dual is basically a generalized cross product. This perspective implies the abstract definition of the Hodge-dual that involves orthogonal subspaces, which is often pulled out of thin air in other presentations. (So maybe prove that the Hodge-dual satisfies this condition involving orthogonal subspaces as a result of it satisfying cross-product like condition. Now that I think about it, this proof will be analogous to proving that $\vv \times \ww$ is perpendicular to $\vv$ and $\ww$ by using the defn of $\times$. This means that definition of Hodge dual will be in cross product section, so can remove definition snear vector calculus stuff).
\end{itemize}

\subsection*{Orientation}

\begin{itemize}
    \item Add intro to orientation section describing what orientation intuitively is and how it connects to notions of clockwise and counterclockwise. (Orientation is a mapping of axes in a diagram to axes in “actual” space. For some reason rotations don’t change orientation.)
    \item Show that two ordered bases are rotationally equivalent $\iff$ there is a CCW rotation taking one to the other $\iff$ there is a CW rotation taking one to the other
\end{itemize}

\subsubsection*{Probably already done}

\begin{itemize}
    \item Remove definition that an “n rotation” is a composition of extensions to 2-rotations. Gives the idea that rotations about arbitrary axes are such compositions, which is true, but isn’t proven at the time of the definition, or even soon after. We don’t need to know that rotations about arbitrary axes are compositions of extensions to 2-rotations to benefit from how they help us formalize the idea of orientation.
    \item Probably get rid of “extension of 2 rotation” and just say “2-rotation”
    \item Could be of help: https://analyticphysics.com/Higher%20Dimensions/Rotations%20in%20Higher%20Dimensions.htm
\end{itemize}

\section*{Manifolds and differential forms}

\subsection*{Finally, a deep understanding of differential forms}

\begin{itemize}
    \item Finish end of story about differential forms; diff forms are wedge products of covector fields because the involvement of $d$ implies involvement of covectors
    \begin{itemize}
        \item \textbf{Do the ``write out this derivation'' thing in diff\_forms\_investigation after the end of the aside.}
    \end{itemize}
    \item Finish aside about tangent vectors. Figure out isomorphism between space of equivalence classes of curves and vector space of derivations. This will probably be helpful: \url{https://people.ucsc.edu/~rmont/classes/ManifoldsI/Lectures/TangentSpace.pdf}
    \item I've been using the notation $\Omega^k \FF^*$ incorrectly. You can't just apply $\Omega^k \FF^*$ to an $\ell$-blade when $\ell \neq k$. Instead, define and use $\Omega \FF^*$ for this purpose.
    
    First define $\Lambda \ff$. $\Lambda \ff$ is a map from the union of all $k$th exterior powers over $V$ to the union of all exterior powers over $W$. So $\Lambda \ff(T)$ is understood to be $\Lambda^k \ff(T)$ for the appropriate $k$. $\Omega \FF^*$ is defined similarly.
    \begin{itemize}
        \item  This might be getting into graded algebra territory.
    \end{itemize}    
    \item Warner is best diff geo book. DEFINITELY better than Lee. Gets to tangent vectors quickly, on like p. 13, and does linear algebra with abstract tensors and wedges (although doesn’t do a great job at explaining the involvement of dual spaces) before using said linear algebra on manifolds. Maybe update citations to reference Warner.
\end{itemize}

Also add this remark from Hubbard and Hubbard somewhere:

\begin{itemize}
    \item Every 1-blade is identifiable with a linear function of the form $\vv \mapsto \ww \cdot \vv$ for some vector $\ww$, which computes the work done by $\ww$ along $\vv$
    \item Every 2-blade is identifiable with an alternating multilinear function of the form $(\vv_1, \vv_2) -> \det(\ww, \vv_1, \vv_2)$ for some vector $\ww$, which computes the flux of $\ww$ through the oriented area $\vv_1 \wedge \vv_2$ (since $\det(\ww, \vv_1, \vv_2) = \ww \cdot (\vv_1 \times \vv_2) = ||\ww|| \sproj(\ww \rightarrow \vv_1 \times \vv_2)$)
    \item Every 3-blade is identifiable with an alternating linear function of the form $(\vv_1, \vv_2, \vv_3) -> \rho \spc \det(\vv_1, \vv_2, \vv_3)$ for some real number $\rho$, which computes the mass of density $\rho$ contained in the oriented volume $\vv_1 \wedge \vv_2 \wedge \vv_3$
\end{itemize}

\subsection*{Finally, a way to formalize the mnemonic}

Thinking about linear combinations of the coordinate function may help me determine what vector space is involved in the theorem about coordinates of vectors and covectors in a chart, Theorem \ref{ch::manifolds::thm::induced_bases_in_a_chart}. Could the key idea be that
$C^\infty(M \rightarrow \R^n)$ is a finite dimensional vector space over $C^\infty(M -> R)$, since for $\FF \in C^\infty(M \rightarrow \R^n)$ we have $\FF = \sum_i F^i x^i$, where $F^i \in C^\infty(M \rightarrow \R)$?


\subsection*{Read \textit{Vector and Tensor Analysis with Applications}}

Read \textit{Vector and Tensor Analysis with Applications} by A.I. Borisenko and I.E. Tarapov to learn about the simple ideas behind things like the covariant derivative.

\begin{itemize}
    \item Q. This book assumes that all changes of bases in $\R^n$ (let's say the bases are $E$ and $F$) can be specified by knowing the dot products $\ee_i \cdot \ff_j$. This leads to the question: in a finite-dimensional vector space $V$ with nondegenerate bilinear form $B$, which changes of basis can be specified by knowing $B(\ee_i, \ff_j)$ for all $i$ and $j$?
\end{itemize}

\subsection*{Etc.}

\begin{itemize}
    
    \item Figure out the unexplained step in Theorem \ref{ch::diff_forms::thm::integral_of_diff_form_actual_function_single_chart}. Somehow, $d\xx \Big( \frac{\pd}{\pd \tx^i_{(V, \yy)}} \Big) = \frac{\pd \xx}{\pd \tx^i_{(V, \yy)}}$. 
    \item Finish the section in ``Manifolds'' on frames and coframes.
    \item Figure out why the ``mnemonic'' of the ``Manifolds'' chapter works.
    \item Add the divergence theorem and the less general Stokes' theorem (and Green's theorem) after the generalized Stokes' theorem.
    \item Potentially relocate the section about differential forms in $\tOmega^k(M)$ that act on tangent vectors. Potentially the presentation of  tensors/differential forms as actual (pointwise) multilinear functions.
    \item Explain more explicitly how the cancellation in part 3 of the proof of \ref{ch::diff_forms::theorem::stokes_on_a_smooth_chart} occurs. (``all the internal boundaries in the sum $\sum_{C \in D_N(\cl(\H^k))} \int_{\pd C}$ cancel, since each boundary appears twice with opposite orientations'').
\end{itemize}