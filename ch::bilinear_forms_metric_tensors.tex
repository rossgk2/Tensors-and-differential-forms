\chapter{Bilinear forms, metric tensors, and coordinates of tensors}
\label{ch::bilinear_forms_metric_tensors}

The goal of this chapter is to present results regarding the coordinates of $(p, q)$ tensors relative to bases. This is accomplished in the second part of this chapter. The first subsection of the second part, ``Coordinates with a metric tensor'', is the most important part of this entire chapter. Particularly important is Theorem \ref{ch::bilinear_forms_metric_tensors::thm::coords_vector_dual_vector},
which describes how vectors and dual vectors can act on each other to produce each other's coordinates. The subsequent subsections of the second part of this chapter are less important, but still interesting. In these, we show how to change the bases of a $(p, q)$ tensor and how composition of linear functions generalizes to \textit{tensor contraction}. Of least (direct) importance is the discussion of the convention of \textit{slanted indices}; we have included this because it is handy to know of when exploring literature on tensors.

We build up to these ideas about coordinates by investigating \textit{bilinear forms} in the first part of the chapter. A special type of bilinear form with which the reader may be familiar is an \textit{inner product}; we will define and investigate various facts about these. If you wish to be economical about reading the first part of this chapter, you can skip the middle two sections (``Inner products'' and ``Symmetric and orthogonal linear functions''); those sections are included for completeness.

\section{Bilinear forms and metric tensors}

\begin{defn}
    (Linear $k$-form, bilinear form).
    
    Let $V_1, ..., V_k$ be vector spaces over a field $K$. A \textit{linear $k$-form on $V_1, ..., V_k$} is\footnote{Unfortunately, the word ``$k$-form'' without the qualifier ``linear'' is reserved to mean \textit{differential} $k$-form. We have not defined differential $k$-forms yet.} a $k$-linear function ${V_1 \times ... \times V_k \rightarrow K}$.
    
    Let $V$ be a vector space over $K$. A \textit{linear $k$-form on $V$} is a linear $k$-form on $V^{\times k}$.
    
    A \textit{bilinear form on $V_1$ and $V_2$} is a linear $2$-form on $V_1$ and $V_2$, and a bilinear form on $V$ is a linear $2$-form on $V$ and $V$, i.e., a bilinear form on $V$ and $V$.
\end{defn}

\begin{remark}
\label{ch::bilinear_forms_metric_tensors::rmk::linear_k_forms_0_k_tensors}

    (Linear $k$-forms are naturally identified with $(0, k)$ tensors).
    
    A linear $k$-form on $V$ is an element of $\LLLL(V^{\times k} \rightarrow K)$. Recalling Theorem \ref{ch::motivated_intro::thm::four_fundamental_isos}, we have $\LLLL(V^{\times k} \rightarrow K) \cong \LLLL(V^{\otimes k} \rightarrow K) = (V^{\otimes k})^* \cong (V^*)^{\otimes k} = T^0_k(V)$. Therefore a linear $k$-form is naturally identified with a $(0, k)$ tensor.
\end{remark}

\begin{defn}
\label{ch::bilinear_forms_metric_tensors::defn::nondegen_bilinear_form}

    (Nondegenerate bilinear form, the natural musical isomorphisms).
    
    Let $V$ and $W$ be finite-dimensional vector spaces. If we have a bilinear form $B$ on $V$ and $W$, then there are natural linear maps $\flat_1:V \rightarrow W^{*}$ and $\flat_2:W \rightarrow V^{*}$ defined\footnote{$B(\vv, \cdot)$ denotes the function $\ww \mapsto B(\vv, \ww)$ and $B(\cdot, \ww)$ denotes the function $\vv \mapsto B(\vv, \ww)$.} by $\flat_1(\vv) := B(\vv, \cdot)$ and $\flat_2(\ww) := B(\cdot, \ww)$. We denote $\vv^{\flat_1} := \flat_1(\vv)$ and $\ww^{\flat_2} := \flat_2(\ww)$.
    
    What would it take for $\flat_1$ and $\flat_2$ to be linear isomorphisms? Well, if we knew that $\flat_1:V \rightarrow W^{*}$ and $\flat_2:W \rightarrow V^{*}$ were linear injections, then we would have $\dim(V) \leq \dim(W)$ and $\dim(W) \leq \dim(V)$, so we would have $\dim(V) = \dim(W)$, that is, $\dim(V) = \dim(W^*) = \dim(W) = \dim(V^*)$. Then, since $\flat_1$ and $\flat_2$ would be one-to-one linear functions between finite-dimensional vector spaces of the same dimension, ontoness would follow automatically, and $\flat_1$ and $\flat_2$ would be linear isomorphisms (see Theorem \ref{ch::lin_alg::thm::linear_fn_1-1_iff_onto}).

    \newpage

    Therefore, if $\flat_1$ and $\flat_2$ are one-to-one, then they are linear isomorphisms. When are $\flat_1$ and $\flat_2$ one-to-one? This is the case if and only if their kernels are $\{\mathbf{0}\}$. In other words, $\flat_1$ and $\flat_2$ are isomorphisms iff the bilinear form $B$ satisfies $(B(\vv, \ww) = \mathbf{0} \iff \vv = \mathbf{0} \text{ for all } \ww \in W)$ and $B((\vv, \ww) = \mathbf{0} \iff \ww = \mathbf{0} \text{ for all } \vv \in V)$, that is, iff
    
    \begin{align*}
        (B(\vv, \ww) = \mathbf{0} \iff \vv = \mathbf{0} \text{ or } \ww = \mathbf{0}) \text{ for all } \vv \in V, \ww \in W.
    \end{align*}
    
    A bilinear form $B$ that satisfies the above condition is called \textit{nondegenerate}. 
    
    We have contrived nondegenerate bilinear forms to be those for which $\flat_1:V \rightarrow W^{*}$ and $\flat_2:W \rightarrow V^{*}$ are natural linear isomorphisms. Note that when $\flat_1$ and $\flat_2$ are isomorphisms, they are indeed natural because they do not depend on a choice of basis (see Definition \ref{ch::lin_alg::defn::natural_iso}). When they are isomorphisms, $\flat_1$ and $\flat_2$ are called the \textit{musical isomorphisms induced by $B$}. We denote the inverses of $\flat_1$ and $\flat_2$ by $\sharp_1$ and $\sharp_2$, respectively: $\sharp_1 = \flat_1^{-1}:W^* \rightarrow V$ and $\sharp_2 = \flat_2^{-1}:V^* \rightarrow W$.
\end{defn}

\begin{proof}
    We have $B(\vv, \ww) = \vv^{\flat_1}(\ww)$. Since the $1 \times m$ matrix $\vv^{\flat_1}(F)$ of $\vv^{\flat_1}:W \rightarrow K$ relative to $F$ is $\vv^{\flat_1}(F) = [\vv^{\flat_1}]_{F^*}^\top$ (recall Theorem \ref{ch::bilinear_forms_metric_tensors::thm::matrix_of_dual_vector_as_trtransposed_coords}), we apply the characterizing property of [...] matrices (see Derivation [...]) and get $B(\vv, \ww) = \vv^{\flat_1}(\ww) = \vv^{\flat_1}(F) [\ww]_F = [\vv^{\flat_1}]_{F^*}^\top [\ww]_F$. So $B(\vv, \ww) = [\vv^{\flat_1}]_{F^*}^\top [\ww]_F$. We know $[\vv^{\flat_1}]_{F^*} = \BB [\vv]_E$ from the fourth equation of Theorem \ref{ch::bilinear_forms_metric_tensors::thm::vectors_dual_vectors_metric_tensor}, so $g(\vv, \ww) = (\BB [\vv]_E)^\top [\ww]_F = [\vv]_E^\top \gg [\ww]_F$, which is the first equation of the first line.
\end{proof}

\begin{theorem}
\label{ch::bilinear_forms_metric_tensors::induced_bilinear_form_on_duals}
    (Induced bilinear form on the duals).
    
    Let $V$ and $W$ be finite-dimensional vector spaces over a field $K$. If $B$ is a nondegenerate bilinear form on $V$ and $W$, then there is an induced nondegenerate bilinear form $\widetilde{B}:W^* \times V^* \rightarrow K$ on $W^*$ and $V^*$ defined by $\widetilde{B}(\psi, \phi) = B(\psi^{\sharp_1}, \phi^{\sharp_2})$. The bilinear form $\widetilde{B}$ induces natural isomorphisms $\widetilde{\flat}_1:V^* \rightarrow W^{**}$, $\widetilde{\flat}_2:W^* \rightarrow V^{**}$ defined by $\phi^{\widetilde{\flat}_1}(\psi) = \widetilde{B}(\psi, \phi)$ and $\psi^{\widetilde{\flat}_2}(\phi) = \widetilde{B}(\psi, \phi)$. (Checking that $\widetilde{B}$ is actually a nondegenerate bilinear form is left an exercise).
\end{theorem}

\begin{lemma}
     Let $V$ and $W$ be finite-dimensional vector spaces with bases $E$ and $F$, let $B$ be a nondegenerate bilinear form on $V$ and $W$, and let $\widetilde{B}$ be the induced nondegenerate bilinear form on $W^*$ and $V^*$. Then 

    \begin{align*}
        B(\vv, \ww) &= [\vv]_E^\top \BB [\ww]_F = [\ww]_F^\top \BB^\top [\vv]_E
        \\
        \widetilde{B}(\psi, \phi) &= [\psi]_{F^*}^\top \widetilde{\BB} [\phi]_{E^*} = [\phi]_{E^*}^\top \widetilde{\BB}^\top [\psi]_{F^*}
    \end{align*}
    
    for all $\vv \in V$, $\ww \in W$, $\phi \in V^*$, and $\psi \in W^*$.
\end{lemma}

\begin{proof}
    
    To show the first equation of the first line, we follow a derivation similar in spirit to that of a matrix relative to bases of a linear function between vector spaces. That is, we first consider the special case in which the vector spaces are $K^n$ and $K^m$, where $K$ is the field, and then use change of basis maps to generalize. So: consider the special case $V = K^n$ and $W = K^m$, where $\sE = \{\see_1, ..., \see_n\}$ and $\sF = \{\sff_1, ..., \sff_m\}$ are the standard bases for $K^n$ and $K^m$. We have $B(\vv, \ww) = \sum_{ij} ([\vv]_\sE)^i ([\ww]_\sE)^j B_{ij} = \sum_{ij} ([\vv]_\sE)^i B_{ij} ([\ww]_\sE)^j = \sum_i ([\vv]_\sE)^i \sum_j B_{ij} ([\ww]_\sE)^j = \sum_i ([\vv]_\sE)^i ([\BB \ww]_\sF)^i = \vv \cdot (\BB \ww) = \vv^\top \BB \ww = [\vv]_\sE^\top \BB [\ww]_\sF^\top$, so the special case is proven. For the case when $V$ and $W$ are $n$- and $m$- dimensional vector spaces with bases $E$ and $F$, consider the bilinear form $C$ on $K^n$ and $K^m$ defined by $C(\vv, \ww) := B([\vv]_E, [\ww]_F)$. By the special case, we have $B(\vv, \ww) = [\vv]_E^\top \CC [\ww]_F$, where $\CC = (C(\ee_i, \ff_j))$. We have $\CC = (C(\ee_i, \ff_j)) = (B([\ee_i]_E, [\ff_i]_F)) = (B(\see_i, \sff_i)) = \BB$, so $B(\vv, \ww) = [\vv]_E^\top \BB [\ww]_F$, as claimed.
    
    The first equation of the second line is obtained by applying the first line to the induced nondegenerate bilinear form $\widetilde{B}$ on $W^*$ and $V^*$, and the second equation on each line follows by transposing the first equation on each line.
\end{proof}
 
\begin{theorem}
\label{ch::bilinear_forms_metric_tensors::thm::matrices_musical_isos}
    (Matrices of the musical isomorphisms).
    
    Let $V$ and $W$ be finite-dimensional vector spaces with bases $E$ and $F$, let $B$ be a bilinear form on $V$ and $W$, and let $E^*$ and $F^*$ be the bases for $V^*$ and $W^*$ induced by $E$ and $F$. We have\footnote{One can refer to $\BB$ as ``the matrix of $B$ relative to $E$ and $F$'' because, as we will see, $\BB$ satisfies a characterizing property similar to the one for the matrix $\ff(E)$ of a linear function ${\ff:U \rightarrow K^m}$, where $U$ is a finite-dimensional vector space over a field $K$. Similarly, $\widetilde{\BB}$ is the matrix of $\widetilde{B}$ relative to $F^*$ and $E^*$.}

    \begin{align*}
        [\flat_1(E)]_{F^*} = \BB^\top \text{ and } [\flat_2(F)]_{E^*} = \BB, \text{ where $\BB := \Big(B(\ee_i, \ee_j)\Big)$} \\
        [\widetilde{\flat_1}(F^*)]_{E^{**}} = (\widetilde{\BB})^\top \text{ and } [\flat_2(E^*)]_{F^{**}} = \widetilde{\BB}, \text{ where $\widetilde{\BB} := \Big(\widetilde{B}(\ee_i, \ee_j)\Big)$}. 
    \end{align*}
\end{theorem}

\begin{proof}
    The first line is true because we have $([\flat_1(E)]_{F^*})^i{}_j = ([\flat_1(\ee_j)]_{F^*})^i = ([\ee_j^{\flat_1}]_{F^*})^i = \ee_j^{\flat_1}(\ff_i) = B(\ee_j, \ff_i)$ and \\ $([\flat_2(F)]_{E^*})^i{}_j = ([\flat_2(\ff_j)]_{E^*})^i = ([\ff_j^{\flat_2}]_{E^*})^i = \ff_j^{\flat_2}(\ee_i) = B(\ee_i, \ff_j)$. The second line follows by applying the first line to the bilinear form $\widetilde{B}:W^* \times V^* \rightarrow K$.
\end{proof}
 
\begin{remark}
    (Indexing conventions for entries of matrices of bilinear forms).
    
    Consider the hypotheses of the previous theorem and additionally assume that $V = W$. Then ${B \in \LLLL(V \times V \rightarrow K)}$, so $B$ can be identified with a $(0, 2)$ tensor on $V$, and $\widetilde{B} \in \LLLL(V^* \times V^* \rightarrow K)$, so $\widetilde{B}$ can be identified with a $(2, 0)$ tensor on $V$. (Recall Remark \ref{ch::bilinear_forms_metric_tensors::rmk::linear_k_forms_0_k_tensors}). To make sure that we are following the convention regarding coordinates of tensors established in Definition \ref{ch::motivated_intro::defn::pq_tensor_coords}, we use $B_{ij}$ to denote the $ij$ entry of the matrix $\BB$ and use $B^{ij}$ to denote the $ij$ entry of the matrix $\widetilde{\BB}$.
\end{remark}
 
\begin{theorem}
    \label{ch::bilinear_forms_metric_tensors::thm::B_Btilde_kind_of_inverses}
    ($\flat_1$ and $\widetilde{\flat}_1$ are ``kind of'' inverses).
    
    Let $V$ and $W$ be finite-dimensional vector spaces over a field $K$ with bases $E$ and $F$, let $E^* = \{\phi^{\ee_1}, ..., \phi^{\ee_n}\}$ and $F^* = \{\psi^{\ff_1}, ..., \psi^{\ff_n}\}$ be the bases for $V^*$ and $W^*$ induced by $E$ and $F$, and let $E^{**}$ and $F^{**}$ be the bases for $V^{**}$ and $W^{**}$ induced by $E^*$ and $F^*$. Lastly, let $B$ be a nondegenerate bilinear form on $V$ and $W$ with induced musical isosmorphisms $\flat_1, \flat_2$, and let $\widetilde{B}$ be the induced nondegenerate bilinear form on $W^*$ and $V^*$ with induced musical isomorphisms $\widetilde{\flat}_1, \widetilde{\flat}_2$.
    
    The musical isomorphisms $\flat_1$ and $\widetilde{\flat}_1$ are ``kind of'' inverses in the following sense:
     
    \begin{enumerate}
         \item $\widetilde{\flat}_1 \circ \flat_1 = (\vv \mapsto \Phi_\vv)$
        \item The matrices of $\widetilde{\flat}_1$ and $\flat_1$ relative to the appropriate bases are inverses: $[\widetilde{\flat}_1(F^*)]_{E^{**}} [\flat_1(E)]_{F^*} = \II$.
        \item $\BB^{-1} = \widetilde{\BB}$, where $\widetilde{\BB} = (\widetilde{B}(\psi^{\ff_i}, \phi^{\ee_j}))$.
    \end{enumerate}
\end{theorem}
 
\begin{proof}
    \hspace{0mm} \\
    \begin{enumerate}
        \item We have: $\widetilde{\flat}_1 \circ \flat_1 = (\vv \mapsto \Phi_\vv) \iff  \Phi_\vv = (\vv^{\flat_1})^{\widetilde{\flat}_1} \iff
        (\Phi_\vv(\phi) (\vv^{\flat_1})^{\widetilde{\flat}_1}(\phi) \text{ for all $\phi \in V^*$}) \\ \iff
        (\phi(\vv) = \widetilde{g}(\vv^{\flat_1}, \phi) = g(\vv, \phi^{\sharp_2}) \text{ for all $\phi \in V^*$})$ \\ $\iff (\phi(\ee_i) = g(\ee_i, \phi^{\sharp_2}) \text{ for all $\phi \in V^*$}) \iff (([\phi]_{E^*})_i = g(\ee_i, \phi^{\sharp_2}) \text{ for all $\phi \in V^*$})$.
        
        \item The matrix of a composition of a linear function is equal to the matrix-matrix product of the matrices (with respect to the appropriate bases) of the functions in the composition, so we have $[\widetilde{\flat}_1 \circ \flat_1]_{E^{**}} = [\widetilde{\flat}_1(F^*)]_{E^{**}} [\flat_1(E)]_{F^*}$. Since $\widetilde{\flat}_1 \circ \flat_1 = (\vv \mapsto \Phi_\vv)$, we can prove the desired fact- that the matrices on the right side of this last equation are inverses- by showing that the matrix of $(\vv \mapsto \Phi_\vv) = \FF$ relative to $E$ and $E^{**}$ is $\II$. To do so, define $\FF(\vv) = \Phi_\vv$, so that the matrix of $(\vv \mapsto \Phi_\vv) = \FF$ relative to $E$ and $E^{**}$ is $[\FF(E)]_{E^{**}}$. The $ij$ entry of this matrix is $([\FF(\ee_j)]_{E^{**}})^i = ([\Phi_{\ee_j}]_{E^{**}})^i = \Phi_{\ee_j}(\phi^{\ee_i})$, where $\phi^{\ee_i}$ denotes the $i$th basis vector in $E^*$. Since $\Phi_{\ee_j}(\phi^{\ee_i}) = \phi^{\ee_i}(\ee_j) = \delta^i{}_j$, the matrix itself is $\II$.
        \item Theorem \ref{ch::bilinear_forms_metric_tensors::thm::matrices_musical_isos} tells us that $[\flat_1(E)]_{F^*} = \BB^\top$ and $[\widetilde{\flat}_1(F^*)]_{E^{**}} = (\widetilde{\BB})^\top$. Using these results with (2), we obtain $(\widetilde{\BB})^\top \BB^\top = \II$. Take the transpose of both sides to obtain $\widetilde{\BB} \BB = \II$, as desired. \textbf{before using transpose have to define symmetric linear function}
    \end{enumerate}
\end{proof}
 
\begin{theorem}
     (Self-dual $\iff$ orthonormal).
     
     Let $V$ be a finite-dimensional vector space with a nondegenerate bilinear form $B$ and a basis $E = \{\ee_1, ..., \ee_n\}$. Let $E^* = \{\phi^{\ee_1}, ..., \phi^{\ee_n}\}$ be the induced dual basis for $V^*$. The musical isomorphism $\flat$ induced by $B$ sends basis vectors to induced dual basis vectors, $\ee_i \mapsto \phi^{\ee_i}$, iff $B(\ee_i, 
     \ee_j) = \delta^i_j$ for all $i, j$. 
     
     In the special case when $B$ is an \textit{inner product}, this means that $\flat$ sends basis vectors to induced dual basis vectors iff $E$ is \textit{orthonormal} with respect to $B$. (We have not defined what an ``inner product'' is or what ``orthonormal'' means yet, but the previous sentence should be immediately clear after we do touch on these concepts).
\end{theorem}

\begin{proof}
    We have: $\ee_i^\flat = \phi^{\ee_i} \iff \ee_i^\flat(\vv) = \phi^{\ee_i}(\vv) \text{ for all $\vv \in V$} \iff \ee_i^\flat(\ee_j) = \phi^{\ee_i}(\ee_j) \iff B(\ee_i, \ee_j) = \phi^{\ee_i}(\ee_j) \iff B(\ee_i, \ee_j) = \delta^i{}_j$.
\end{proof}

\begin{remark}
\label{ch::bilinear_forms_metric_tensors::thm::musical_iso_unique_self_dual_iso}
    (Naturality of self-duality).

    The above theorem shows that the ``unnatural'' isomorphism $V \rightarrow V^*$ sending $\ee_i \mapsto \phi^{\ee_i}$ that was discussed earlier in Remark \ref{ch::motivated_intro::rmk::unnatural_iso_V_V*} actually becomes natural exactly whenever we have a bilinear form $B$ on $V$ and $B(\ee_i, \ee_j) = \delta^i_j$.
\end{remark}

\subsection*{Inner products}

\begin{defn}
    (Metric tensor).
    
    Let $V$ be a finite-dimensional vector space. A nondegenerate bilinear form on $V$ that is also \textit{symmetric}, in the sense that $g(\vv_1, \vv_2) = g(\vv_2, \vv_1)$ for all $\vv_1, \vv_2 \in V$, is called a \textit{metric tensor on $V$}.
\end{defn}

\begin{defn}
    (The notation $\flat$ and $\sharp$).
    
    When $V$ is a finite-dimensional vector space and there is a metric tensor $g$ on $V$, then the musical isomorphisms ${\flat_1:V \rightarrow V^*}$ and ${\flat_2:V \rightarrow V^*}$ induced by $g$ are the same because $g$ is symmetric. In this scenario, we define $\flat := \flat_1 = \flat_2$ and $\sharp := \sharp_1 = \flat_1^{-1} = \sharp_2 = \flat_2^{-1}$.
\end{defn}

\begin{defn}
    (Inner product).
    
    A metric tensor $g$ on $V$ is an \textit{inner product} on $V$ iff it is also \textit{positive-definite}, that is, iff it is a metric tensor that satisfies $g(\vv, \vv) \geq 0$ for all $\vv \in V$, with $g(\vv, \vv) = \mathbf{0}$ iff $\vv = \mathbf{0}$.
    
    Iff $g$ is an inner product, we denote it by $\langle \cdot, \cdot \rangle$ and use the notation $\langle \vv_1, \vv_2 \rangle := g(\vv_1, \vv_2)$, for $\vv_1, \vv_2 \in V$.
\end{defn}

\begin{defn}
    (Inner product space).
    
    Let $V$ be a vector space over $K$. Iff there is an inner product $\langle \cdot, \cdot \rangle$ on $V$, then $V$ is called a \textit{vector space with inner product}, or an \textit{inner product space}.
\end{defn}

\begin{remark}
    (Positive-definite $\implies$ nondegenerate, but the converse does not hold).
    
    The first part of the title of this remark is straightforwardly checked by looking at the definition of nondegenerate bilinear form. Therefore, all inner products are metric tensors, but not all metric tensors are inner products.
\end{remark}

\begin{example}
    The dot product on $\R^n$ is an inner product on $\R^n$. (Proof left as exercise). 
    
    The dot product on $K^n$, defined analogously to the dot product on $\R^n$, is in general \textit{not} an inner product because it is not positive-definite. For example, we have $\begin{pmatrix} 3 \\ 3 \end{pmatrix} \cdot \begin{pmatrix} 3 \\ 3 \end{pmatrix} = 0$ when these vectors are elements of $\Z/9\Z$. (In $\Z/9\Z$, we have $3 \cdot 3 = 9 = 0$).
\end{example}

\subsubsection*{Length and orthogonality with respect to an inner product}

\begin{defn}
    (Length of a vector with respect to an inner product). 
    
    Let $V$ be an inner product space. In analogy to the fact that the length of a vector in $\R^n$ can be expressed using the dot product on $\R^n$ (see Theorem \ref{ch::lin_alg::thm::length_in_Rn}), we define the \textit{length of a vector $\vv \in V$ with respect to the inner product on $V$} to be $||\vv|| := \sqrt{\langle \vv, \vv \rangle}$.
\end{defn}

\begin{defn}
    (Angle between vectors with respect to an inner product). 
    
    Let $V$ be an inner product space. In analogy to the the fact that the angle between vectors $\vv_1, \vv_2 \in \R^n$ is $\arccos(\hat{\vv}_1 \cdot \hat{\vv}_2)$, we define the \textit{angle $\theta$ between vectors $\vv_1, \vv_2 \in V$ with respect to the inner product on $V$} to be $\theta := \arccos(\langle \hat{\vv}_1, \hat{\vv}_2 \rangle)$. Note that $\hat{\vv}_i = \frac{\vv_i}{||\vv_i||} = \frac{\vv_i}{\sqrt{\langle \vv_i, \vv_i \rangle}}$.
\end{defn}

\begin{remark}
    (Geometric inner product).
    
    Let $V$ be an inner product space. Then $\langle \vv_1, \vv_2 \rangle = ||\vv_1||\spc||\vv_2|| \cos(\theta)$, where $\theta$ is the angle between $\vv_1$ and $\vv_2$ with respect to the inner product on $V$. (This fact is the generalization of the geometric dot product on $\R^n$, which was discussed in Theorem \ref{ch::lin_alg::thm::dot_prod_and_angle}).
\end{remark}

\begin{theorem}
\label{ch::bilinear_forms_metric_tensors::thm::Cauchy_Schwarz}
     (Cauchy-Schwarz inequality for vector spaces over $\R$).
     
     Let $V$ be a vector space over $\R$ with inner product. Then the \textit{Cauchy-Schwarz inequality} holds: $\langle \vv_1, \vv_2 \rangle \leq ||\vv_1|| \spc ||\vv_2||$ for all $\vv_1, \vv_2 \in V$. 
     
     Note, the Cauchy-Schwarz inequality is equivalent to the statement that the angle $\theta$ in $V$ between $\vv_1$ and $\vv_2$ with respect to the inner product on $V$ satisfies $\theta \in [0, 2 \pi)$.
\end{theorem}

\begin{proof}
    Define $f:\R \rightarrow [0, \infty) \subseteq \R$ by $f(k) = \langle k \vv_1 + \vv_2, k \vv_1 + \vv_2 \rangle = k^2 \langle \vv_1, \vv_1 \rangle + 2 k \langle \vv_1, \vv_2 \rangle + \langle \vv_2, \vv_2 \rangle$. Set $a := \langle \vv_1, \vv_1 \rangle$, $b := 2 \langle \vv_1, \vv_2 \rangle$, and $c := \langle \vv_2, \vv_2 \rangle$, so that $f(k) = ak^2 + bk + c$.
    
    Since $\langle \cdot, \cdot \rangle$ is positive-definite, then $f$ is nonnegative, and therefore must have either one or zero real roots. According to the quadratic formula, one real root occurs when $b^2 - 4ac = 0$, and zero real roots occur when $b^2 - 4ac < 0$. So, we must have $b^2 - 4ac \leq 0$. 
    
    Using our expressions for $a, b$, and $c$, we see that $(4 \langle \vv_1, \vv_2 \rangle)^2 - 4(\langle \vv_1, \vv_2 \rangle)(\langle \vv_2, \vv_2 \rangle) \leq 0$. Thus \\ ${\langle \vv_1, \vv_2 \rangle^2 \leq \langle \vv_1, \vv_1 \rangle \langle \vv_2, \vv_2 \rangle = ||\vv_1||^2 ||\vv_2||^2}$. Take the square root of each side to obtain the result.  
\end{proof}

\begin{defn}
    (Orthogonality of vectors with respect to an inner product). 
    
    Let $V$ be an inner product space. We say vectors $\vv_1, \vv_2 \in V$ are \textit{orthogonal with respect to the inner product on $V$} iff the angle between $\vv_1$ and $\vv_2$ is $\frac{\pi}{2}$. That is, $\vv_1, \vv_2 \in V$ are orthogonal iff $\langle \vv_1, \vv_2 \rangle = 0$.
\end{defn}

\begin{defn}
    (Orthonormal basis with respect to an inner product).
    
     Let $V$ be a finite-dimensional vector space with inner product $\langle \cdot, \cdot \rangle$. We say a basis $E = \{\ee_1, ..., \ee_n\}$ of $V$ is \textit{orthonormal (with respect to $\langle \cdot, \cdot \rangle$)} iff
     
     \begin{itemize}
         \item $||\ee_i|| = 1$ for all $i$
         \item $\ee_i$ and $\ee_j$ are orthogonal to each other when $i \neq j$
     \end{itemize}
     
     That is, $E$ is an orthonormal basis iff $\langle \ee_i, \ee_j \rangle = \delta^i{}_j$ for all $i, j$.
\end{defn}

\begin{theorem}
\label{ch::bilinear_forms_metric_tensors::theorem::Gram-Schmidt}
    (Gram-Schmidt algorithm).
    
    Let $V$ be a finite-dimensional inner product space. Given any basis $E = \{\ee_1, ..., \ee_n\}$ for $V$, we can use the following \textit{Gram-Schmidt algorithm} to convert $E$ into an orthonormal basis $\hU = \{\huu_1, ..., \huu_n\}$.
    
    First, we ``orthogonalize'' the basis $E$ into a basis $F = \{\ff_1, ..., \ff_n\}$. Set $\ff_1 := \ee_1$, and, for $i \geq 2$, set
    
    \begin{align*}
        \ff_i := \ee_i - \proj(\ff_i \rightarrow \spann(\ee_1, ..., \cancel{\ee_i}, ..., \ee_n)) = \ee_i - \sum_{j \neq i} \proj(\ff_i \rightarrow \ee_j) = \ee_i - \sum_{j \neq i} \frac{\langle \ff_i, \ee_j \rangle}{\langle \ee_j, \ee_j \rangle}, \quad i \geq 2.
    \end{align*}
    
    (In the last equality in the line above, we've used an analogue of Theorem \ref{ch::lin_alg::thm::vector_proj_dot_product} to express vector projections in terms of inner products). 
    To obtain the orthonormal basis $\hU = \{\huu_1, ..., \huu_n\}$, we just normalize the orthogonal basis $F$, and set $\huu_i := \frac{\ff_i}{||\ff_i||}$.
\end{theorem}

\subsection*{Symmetric and orthogonal linear functions}

This subsection is presented only for completeness, so reading the entirety of this subsection is not necessary. The only results that are necessary to know are the conditions (3) and (4) of Definition \ref{ch::bilinear_forms_metric_tensors::defn::orthogonal_linear_fn} satisfied by an orthogonal linear function.

\begin{deriv}
\label{ch::bilinear_forms_metric_tensors::defn::dual_transf_after_id}
    (The adjoint of a linear function with respect to a nondegenerate bilinear form).
    
    Let $V$ and $W$ be finite-dimensional vector spaces, let $B$ be a nondegenerate bilinear form on $V$ and $W$, and consider the musical isomorphisms $\flat_1:V \rightarrow W^{*}$ and $\flat_2:W \rightarrow V^{*}$ induced by $B$.
    
    There is an induced linear map $\ff^\dag:V \rightarrow W$, called the \textit{adjoint of $\ff$ (with respect to $B$)}, that is obtained by using the musical isomorphisms on the domain and codomain of the dual transformation $\ff^*:W^* \rightarrow V^*$. We define $\ff^\dag$ to be the unique map for which the following diagram commutes:
    
    \begin{center}
       % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRADUQBfU9TXfIRRkAjFVqMWbAOoA9AFTdeIDNjwEiI0mOr1mrRBwVK+awZvLi9Uw9O7iYUAObwioAGYAnCAFskZEBwIJC0QBjoAIxgGAAV+dSEQTywnAAscEF1JAxAAHVz3cIyeD28-RFCgpAAmanCo2PjzQ2S0jKz9Nnz3d2MSkC9ff2oqxABmOsjouLMNQwYYd3aJTsN8pycTAbKkCcDgxGquCi4gA
        \begin{tikzcd}
        V \arrow[d, "\flat_1"'] \arrow[r, "\ff^\dag"] & W \arrow[d, "\flat_2"] \\
        W^* \arrow[r, "\ff^*"']                & V^*        
        \end{tikzcd}
    \end{center}
    
    Thus, $\ff^\dag = \flat_2^{-1} \circ \ff^* \circ \flat_1$, or, equivalently, $\flat_2 \circ \ff^\dag = \ff^* \circ \flat_1$.
    
    Since $\flat_2 \circ \ff^\dag = \ff^* \circ \flat_1$, then $\ff^\dag(\vv_0)^{\flat_2} = \ff^*(\vv_0^{\flat_1})$. Using the definition of $\ff^*$ (recall Definition \ref{ch::motivated_intro::defn::dual_transf}), we have $\ff^\dag(\vv_0)^{\flat_2} = \vv_0^{\flat_1} \circ \ff$. This is the same\footnote{Here we've used $B(\cdot, \vv_2)$ to denote the function $\vv_1 \mapsto B(\vv_1, \vv_2)$.} as $B(\cdot, \ff^\dag(\vv_0)) = B(\vv_0, \cdot) \circ \ff$. After evaluating both sides of this most recent equation on $\vv_1 \in V$ and relabeling $\vv_0$ as $\vv_2$, we have:
    
    \begin{align*}
        B(\vv_1, \ff^\dag(\vv_2)) = B(\vv_2, \ff(\vv_1)) \text{ for all $\vv_1, \vv_2 \in V$}.
    \end{align*}
\end{deriv}

Replacing the bilinear form of the above derivation with an inner product, we see that when we have an inner product instead of an arbitrary nondegenerate bilinear form, then $\ff^\dag$ is uniquely characterized by the condition that $\langle \vv_1, \ff^\dag(\vv_2) \rangle = \langle \vv_2, \ff(\vv_1) \rangle$ for all $\vv_1, \vv_2 \in V$. We will use this condition as a means to characterize special classes of linear functions. Specifically, we consider linear functions $\ff$ for which $\ff = \ff^\dag$ and for which $\ff^\dag = \ff^{-1}$. Before investigating such linear functions, we quickly present a definition.

\begin{defn}
    (Transpose of a matrix).
    
    The \textit{transpose} of an $m \times n$ matrix $(a^i{}_j)$ is the $n \times m$ matrix $(a^j{}_i)$. The tranpose of a matrix $\AA$ is denoted $\AA^\top$.
\end{defn}

Now, we consider linear functions $\ff$ for which $\ff = \ff^\dag$ and for which $\ff^\dag = \ff^{-1}$.

\begin{defn} 
\label{ch::bilinear_forms_metric_tensors::defn::symmetric_linear_fn}
    (Symmetric linear function).

    Let $V$ be a vector space, consider a linear function $\ff:V \rightarrow V$. We define $\ff$ to be \textit{symmetric} iff the following equivalent conditions hold:
    
    \begin{enumerate}
        \item $\ff = \ff^\dag$.
        \item $\langle \ff(\vv_1), \vv_2 \rangle = \langle \vv_1, \ff(\vv_2) \rangle$ for all $\vv_1, \vv_2 \in V$.
        \item If $V$ is finite-dimensional and $\hU$ is an orthonormal basis of $V$, then the matrix of $\ff$ relative to $\hU$ is equal to its transpose: $[\ff(\hU)]_{\hU}^\top = [\ff(\hU)]_{\hU}$. (Matrices that are equal to their own transpose are called \textit{symmetric}).
    \end{enumerate}
\end{defn}
        
\begin{proof}
    \mbox{} We need to show that the conditions are indeed equivalent.
    \\ \indent ($1 \iff 2$).
    \\ \indent ($\implies$). Use $\ff = \ff^\dag$ with $\langle \vv_1, \ff^\dag(\vv_2) \rangle = \langle \vv_2, \ff(\vv_1) \rangle$. 
    \\ \indent ($\impliedby$). We have $\langle \ff(\vv_1), \vv_2 \rangle = \langle \vv_1, \ff(\vv_2) \rangle$ for all $\vv_1, \vv_2 \in V$ and $\langle \vv_1, \ff^\dag(\vv_2) \rangle = \langle \vv_2, \ff(\vv_1) \rangle$. Therefore $\langle \vv_1, \ff(\vv_2) \rangle = \langle \vv_1, \ff^\dag(\vv_2) \rangle$. Due to the cancelability of inner products (this follows from the positive-definiteness of inner products), we have $\ff(\vv_2) = \ff^\dag(\vv_2)$ for all $\vv_2 \in V$. So $\ff = \ff^\dag$. 

    ($2 \iff $ 3). 
    \\ \indent ($\implies$). If (2) is true, then the $j$th column of $[\ff(\hU)]_{\hU}$ is $[\ff(\huu_j)]_{\hU}$, so the $^i_j$ entry of $[\ff(\hU)]_{\hU}$ is $\langle \ff(\huu_j), \huu_i \rangle$. Similarly, the $^i_j$ entry of the matrix of $\ff^\dag$ relative to $\hU$ is $\langle 
    \ff^\dag(\huu_j), \huu_i \rangle$. Due to the condition on $\langle \cdot, \cdot \rangle$ induced by the identification $V \cong V^*$, we have $\langle \ff^\dag(\huu_j), \huu_i \rangle = \langle \huu_j, \ff(\huu_i) \rangle = \langle \ff^\dag(\huu_i), \huu_j \rangle$. But this is the $^j_i$ entry of $[\ff(\hU)]_{\hU}$, i.e., the $^i_j$ entry of $[\ff(\hU)]_{\hU}^{\top}$. Thus $[\ff(\hU)]_{\hU} = [\ff(\hU)]_{\hU}^{\top}$.
    \\ \indent ($\impliedby$). Let $\hU = \{\huu_1, ..., \huu_n\}$ be an orthonormal basis for $V$, and let the matrix $\AA$ of $\ff$ relative to $\hU$ satisfy $a_{ij} = a^j_i$. Since $a^i{}_j = \langle \ff(\huu_i), \huu_j \rangle$, then $\langle \ff(\huu_i), \huu_j \rangle = \langle \huu_i, \ff(\huu_j) \rangle$. Extend with multilinearity to obtain the conclusion.
\end{proof}

\begin{defn}
\label{ch::bilinear_forms_metric_tensors::defn::orthogonal_linear_fn}
    (Orthogonal linear function). 
    
    Let $V$ be a vector space over $K$ (where\footnote{This is a very technical condition, and not much attention should be paid to it. We require this so that $2 \neq 0$, which allows us to divide by $2$.} we have $K \neq \Z/2\Z$), consider a linear function $\ff:V \rightarrow V$. We define $\ff$ to be \textit{orthogonal} iff the following equivalent conditions hold:
    
    \begin{enumerate}
        \item $\ff^\dag = \ff^{-1}$.
        \item $\langle \ff(\vv_1), \vv_2 \rangle = \langle \vv_1, \ff^{-1}(\vv_2) \rangle$ for all $\vv_1, \vv_2 \in V$.
        \item $\ff$ preserves inner product: $\langle \vv_1, \vv_2 \rangle = \langle \ff(\vv_1), \ff(\vv_2) \rangle$.
        \item $\ff$ preserves length.
        \item $\ff$ preserves length and angle.
        \item If $V$ is finite-dimensional and $\hU$ is an orthonormal basis of $V$, then the matrix $[\ff(\hU)]_{\hU}$ of $\ff$ relative to $\hU$ has orthonormal columns.
        \item If $V$ is finite-dimensional and $\hU$ is an orthonormal basis of $V$, then $[\ff(\hU)]_{\hU}^{-1} = [\ff(\hU)]_{\hU}^{\top}$.
    \end{enumerate}
\end{defn}
        
\begin{proof}
    We need to show that the conditions are indeed equivalent. To do so, we prove $(3) \iff (4) \iff (5)$ and then $(1) \iff (2) \iff (3) \iff (6) \iff (7)$.
    
    \vspace{.2cm}
    
    Here is the proof that $(3) \iff (4) \iff (5)$:
    \\ \indent $(3 \implies 4)$. Length is a function of inner product, $||\vv|| = \sqrt{\langle \vv, \vv \rangle}$. Therefore, if inner product is preserved, then length is preserved.
    \\ \indent $(4 \iff 5)$. The reverse direction is obvious; we need to show the forward direction. The angle $\theta$ between $\vv_1$ and $\vv_2$ is $\theta = \cos^{-1}\Big(\frac{\vv_1 \cdot \vv_2}{||\vv_1||||\vv_2||}\Big)$. Since $\theta$ is a function of preserved quantities (dot product and length), it too is a preserved quantity.
    \\ \indent $(5 \implies 3)$. Replace the dot product $\cdot$ on $\R^n$ with the inner product $\langle \cdot, \cdot \rangle$ on $V$ in the equation stated in the proof of Lemma \ref{ch::lin_alg::lemma::orthogonal_linear_fns_preserve_alg_dot_product} to show that $\langle \vv_1, \vv_2 \rangle = \frac{1}{2}(||\vv_1 + \vv_2||^2 - (||\vv_1||^2 + ||\vv_2||^2))$. That is, the inner product $\langle \vv_1, \vv_2 \rangle$ is a function of $||\vv_1||$ and $||\vv_2||$. Applying the previous formula, the inner product $\langle \ff(\vv_1), \ff(\vv_2) \rangle$ is a function of $||\ff(\vv_1)||$ and $||\ff(\vv_2)||$: ${\langle \ff(\vv_1), \ff(\vv_2) \rangle = \frac{1}{2}(||\ff(\vv_1) + \ff(\vv_2)||^2 - (||\ff(\vv_1)||^2 + ||\ff(\vv_2)||^2))}$. Since $\ff$ is linear, this becomes $\frac{1}{2}(||\ff(\vv_1 + \vv_2)||^2 - (||\ff(\vv_1)||^2 + ||\ff(\vv_2)||^2))$. If length is preserved, then this is the same as $\frac{1}{2}(||\vv_1 + \vv_2||^2 - (||\vv_1||^2 + ||\vv_2||^2) = \langle \vv_1, \vv_2 \rangle$.

    \vspace{.2cm}

    Now we show $(1) \iff (2) \iff (3) \iff (6) \iff (7)$.
    \mbox{} \\
        ($1 \iff 2$).
        \\ \indent ($\implies$). Use $\ff^\dag = \ff^{-1}$ with $\langle \vv_1, \ff^\dag(\vv_2) \rangle = \langle \vv_2, \ff(\vv_1) \rangle$.
        \\ \indent($\impliedby$). $\langle \vv_1, \ff^{-1}(\vv_2) \rangle = \langle \ff(\vv_1), \vv_2 \rangle$ by hypothesis, and $\langle \ff(\vv_1), \vv_2 \rangle = \langle \vv_1, \ff^\dag(\vv_2) \rangle$ by condition on $\langle \cdot, \cdot \rangle$ imposed by identifying $V \cong V^*$ for $\ff^\dag$. Thus $\langle \vv_1, \ff^{-1}(\vv_2) \rangle = \langle \vv_1, \ff^\dag(\vv_2) \rangle$.
        \\ ($2 \implies 3$). Substitute $\vv_3 = \ff^{-1}(\vv_2)$, so that we have $\langle \ff(\vv_1), \ff(\vv_3) \rangle = \langle \vv_1, \vv_3 \rangle$ for all $\vv_1, \vv_3 \in V$.
        \\ ($3 \iff 6$). 
        \\ \indent $(\implies$). We have in particular that $\langle \ff(\huu_i), \ff(\huu_j) \rangle = \langle \huu_i, {\uu}_j \rangle$. Since $\hU$ is orthonormal, $\langle \huu_i, \huu_j \rangle = \delta^i{}_j$. Therefore $\langle \ff(\huu_i), \ff(\huu_j) \rangle = \delta^i{}_j$, so the columns $[\ff(\huu_i)]_{\hU}$ of the matrix of $\ff$ relative to $\hU$ are orthonormal.
        \\ \indent $(\impliedby)$. Since the columns $[\ff(\huu_i)]_{\hU}$ of the matrix of $\ff$ relative to $\hU$ are orthonormal, we have $\langle \ff(\huu_i), \ff(\huu_j) \rangle = \delta^i{}_j$. Extend with multilinearity to obtain the conclusion.
        \\ ($6 \iff 7$).
        \\ \indent $(\implies$). The $^i_j$ entry of $[\ff(\hU)]_{\hU} [\ff(\hU)]_{\hU}^\top$ is $(\text{$i$th row of $[\ff(\hU)]_{\hU}$}) \cdot (\text{$j$th column of $[\ff(\hU)]_{\hU}$})\top = (\text{$i$th row of $[\ff(\hU)]_{\hU}$}) \cdot (\text{$j$th row of $[\ff(\hU)]_{\hU}$}) = \langle \ff(\huu_i), \ff(\huu_j) \rangle = \delta^i{}_j$. Therefore $[\ff(\hU)]_{\hU} [\ff(\hU)]_{\hU}^\top = \II$. A similar argument shows $[\ff(\hU)]_{\hU}^\top [\ff(\hU)]_{\hU} = \II$.
        \\ \indent $(\impliedby)$. Reversing the logic of the forward direction, we know $\langle \ff(\huu_i), \ff(\huu_j) \rangle = \delta^i{}_j$. Therefore (3) is satisfied. Then we use $(3) \implies (6)$.
        \\ ($5 \implies 1$). Use the fact that $[\ff(\hU)]_{\hU}^\top$ is the matrix of the adjoint $\ff^\dag:V \rightarrow V$.
\end{proof}

\newpage

\section{Coordinates of $(p, q)$ tensors}

\label{ch::bilinear_forms_metric_tensors::coords_of_pq_tensors}

\begin{theorem}
\label{ch::bilinear_forms_metric_tensors::thm::coords_vector_dual_vector}
    (Coordinates of vectors and dual vectors).

    Let $V$ be a finite-dimensional vector space, let $E = \{\ee_1, ..., \ee_n\}$ be a basis for $V$, and let $E^* = \{\phi^{\ee_1}, ..., \phi^{\ee_n}\}$ be the basis for $V^*$ induced by $E$.
    
    We have

    \begin{empheq}[box = \fbox]{align*}
        ([\vv]_E)^i &= \phi^{\ee_i}(\vv) = \Phi_\vv(\phi^{\ee_i}) = ([\Phi_\vv]_{E^{**}})^i \\
        ([\phi]_{E^*})_i &= \phi(\ee_i)
    \end{empheq}

    Recall from Theorem \ref{ch::motivated_intro::thm::V_iso_double_dual} that $\vv$ is naturally identified with $\Phi_\vv \in V^{**}$ defined by $\Phi_\vv(\phi) = \phi(\vv)$.
    
    When trying to remember this theorem, it may help to involve the contraction map $C:V \times V^* \rightarrow K$ defined by $C(\vv, \phi) = \phi(\vv)$, since we have the following:
    
    \begin{align*}
        ([\vv]_E)^i &= C(\vv, \phi^{\ee_i}) \\
        ([\phi]_{E^*})_i &= C(\ee_i, \phi).
    \end{align*}
    
    In other words, we take the $i$th coordinate of a vector by contracting that vector with the relevant dual basis vector, and we take the $i$th coordinate of a dual vector by contracting that dual vector with the relevant ``regular'' basis vector.
\end{theorem}

\begin{proof}
    First, we prove the first equation in the first line, $([\vv]_E)^i = \phi^{\ee_i}(\vv)$:
    
    \begin{align*}
        \phi^{\ee_i}(\vv) = \phi^{\ee_i}\Big( \sum_{j = 1}^n ([\vv]_E)^j \ee_i \Big) = \sum_{j = 1}^n \Big( ([\vv]_E)^j \phi^{\ee_i}(\ee_j) \Big) = \sum_{j = 1}^n ([\vv]_E)^j \delta^i{}_j = ([\vv]_E)^i.
    \end{align*}
    
    Now we prove the second line. By definition of $[\cdot]_{E^*}$, any $\phi \in V^*$ is of the form $\phi = \sum_{j = 1}^n ([\phi]_{E^*})_j \phi^{\ee_j}$, so we can compute $\phi(\ee_i)$ as
    
    \begin{align*}
        \phi(\ee_i) = \Big( \sum_{j = 1}^n ([\phi]_{E^*})_j \phi^{\ee_j} \Big)(\ee_i) = \sum_{j = 1}^n \Big( ([\phi]_{E^*})_j \phi^{\ee_j}(\ee_i)\Big) = \sum_{j = 1}^n ([\phi]_{E^*})_j \delta^j{}_i = ([\phi]_{E^*})_i.
    \end{align*}
    
    Now we prove the second equality of the first line. Recall from Theorem \ref{ch::motivated_intro::thm::V_iso_double_dual} that $\Phi_\vv$ is defined as $\Phi_\vv(\phi) := \phi(\vv)$. Therefore $\phi^{\ee_i}(\vv) = \Phi_\vv(\phi^{\ee_i})$. By applying the second line, we then have $\Phi_\vv(\phi^{\ee_i}) = ([\Phi_\vv]_{E^{**}})^i$.
\end{proof}

\begin{theorem}
    \label{ch::bilinear_forms_metric_tensors::thm::matrix_of_dual_vector_as_trtransposed_coords}
    
    (Matrix of dual vector as transposed coordinates).
    
    Let $V$ be a finite-dimensional vector space, let $E = \{\ee_1, ..., \ee_n\}$ be a basis for $V$, let $\sE$ be the standard basis for $K^n$, and consider an element $\phi \in V^*$. Then the matrix $\phi(E)$ of $\phi$ relative to $E$ and $\sE$ (see Remark \ref{ch::lin_alg::rmk::primitive_matrix_as_matrix_wrt_bases}) is $\phi(E) = [\phi]_{E^*}^\top$.
\end{theorem}

\begin{proof}
    The matrix of $\phi$ relative to $E$ and $\sE$ is
    
    \begin{align*}
        \phi(E) 
        = 
        \begin{pmatrix} 
            \phi(\ee_1) & \hdots & \phi(\ee_n)
        \end{pmatrix}
    \end{align*}.

    On the other hand, the previous theorem tells us that coordinates of $\phi$ relative to $E^*$ are
    
    \begin{align*}
        [\phi]_{E^*}
        =
        \begin{pmatrix} 
            ([\phi]_{E^*})_1 \\ \vdots \\ ([\phi]_{E^*})_n
        \end{pmatrix}
        =
        \begin{pmatrix} 
            \phi(\ee_1) \\ \vdots \\ \phi(\ee_n)
        \end{pmatrix}.
    \end{align*}
    
    Inspecting the two above results shows that $\phi(E) = [\phi]_{E^*}^\top$.
\end{proof}

\subsection*{Coordinates with nondegenerate bilinear form}

\begin{theorem}
\label{ch::bilinear_forms_metric_tensors::thm::vectors_dual_vectors_metric_tensor}

    (Relationship between coordinates of vectors and dual vectors for vector spaces).
    
    Let $V$ and $W$ be finite-dimensional vector spaces over a field $K$ with bases $E$ and $F$, let $E^* = \{\phi^{\ee_1}, ..., \phi^{\ee_n}\}$ and $F^* = \{\psi^{\ff_1}, ..., \psi^{\ff_n}\}$ be the bases for $V^*$ and $W^*$ induced by $E$ and $F$, and let $E^{**}$ and $F^{**}$ be the bases for $V^{**}$ and $W^{**}$ induced by $E^*$ and $F^*$. Lastly, let $B$ be a nondegenerate bilinear form on $V$ and $W$ with induced musical isosmorphisms $\flat_1, \flat_2$, and let $\widetilde{B}$ be the induced nondegenerate bilinear form on $W^*$ and $V^*$ with induced musical isomorphisms $\widetilde{\flat}_1, \widetilde{\flat}_2$. 

    Then we have
    
    \begin{align*}
        [\vv]_E = \BB^{-\top} [\vv^{\flat_1}]_{F^*} &\text{ and }
        [\ww]_F = \BB^{-1} [\ww^{\flat_2}]_{E^*} \\
        [\phi]_{E^*} = \BB [\phi^{\sharp_2}]_F &\text{ and }
        [\psi]_{F^*} = \BB^\top [\psi^{\sharp_1}]_E,
    \end{align*}
    
    for all $\vv \in V$, $\ww \in W$, $\phi \in V^*$, and $\psi \in W^*$, where $\BB = (B(\ee_i, \ee_j))$ and $\widetilde{\BB} = (\widetilde{B}(\psi^{\ff_i}, \phi^{\ee_j}))$.
\end{theorem}

\begin{proof}
    We will prove (1) that $[\psi]_{F^*} = \BB [\psi^{\sharp_1}]_E$ for all $\psi \in W^*$ and (2) that $[\vv]_E = \BB^{-1} [\vv^{\flat_1}]_{F^*}$ for all $\vv \in V$. The equation involving $\phi \in V^*$ and $\BB$ is obtained by applying (1) to the nondegenerate bilinear form $C$ on $W$ and $V$ defined by $C(\ww, \vv) := B(\vv, \ww)$, and the equation involving $\ww \in W$ and $\BB^{-1}$ is similarly obtained by applying (2) to the nondegenerate bilinear form $\widetilde{C}$ on $V^*$ and $W^*$ defined by $\widetilde{C}(\phi, \psi) := \widetilde{B}(\psi, \phi)$.

    First, we prove that $[\psi]_{F^*} = \BB [\psi^{\sharp_1}]_E$ for all $\psi \in W^*$. Recall from Definition [...] that the matrix $[\flat_1(E)]_{F^*}$ of $\flat_1:V \rightarrow W^*$ relative to $E$ and $F^*$ satisfies the characterizing property $[\flat_1(\vv)]_{F^*} = [\flat_1(E)]_{F^*} [\vv]_E$ for all $\vv \in V$. That is, $[\vv^{\flat_1}]_{F^*} = [\flat_1(E)]_{F^*} [\vv]_E$ for all $\vv \in V$. We know from Theorem \ref{ch::bilinear_forms_metric_tensors::thm::matrices_musical_isos} that $[\flat_1(E)]_{F^*} = \BB^\top$, so we have $[\vv^{\flat_1}]_{F^*} = \BB^\top [\vv]_E$. Since $\flat_1$ is an isomorphism, we can replace $\vv^{\flat_1} \in W^*$ with an arbitrary $\psi \in W^*$ to obtain $([\psi]_{F^*} = \BB^\top [\psi^{\sharp_1}]_E \text{ for all } \psi \in W^*)$, as desired.
    
    Now we prove $[\vv]_E = \BB^{-\top} [\vv^{\flat_1}]_{F^*}$ for all $\vv \in V$. Applying (1) to the induced nondegenerate bilinear form $\widetilde{B}:W^* \times V^* \rightarrow K$, we obtain an analogous statement to (1) in which $\psi \in W^*$ is replaced with $\Phi \in V^{**}$, $F^*$ is replaced with $E^{**}$, $E$ is replaced with $F^*$, $\sharp_1:W^* \rightarrow V$ is replaced with $\widetilde{\sharp}_1:V^{**} \rightarrow W^*$, and $\BB$ is replaced with $\widetilde{\BB}$: we have $[\Phi]_{E^{**}} &= \widetilde{\BB}^\top [\Phi^{\sharp_1}]_{F^*}$ for all $\Phi \in V^{**}$. Substitute $\Phi_\vv$ in for $\Phi$ and use the fact $([\Phi_\vv]_{E^{**}})^i = ([\vv]_E)^i$ from Theorem \ref{ch::bilinear_forms_metric_tensors::thm::coords_vector_dual_vector} to obtain the statement ``$[\vv]_E = \widetilde{\BB}^\top [\Phi_\vv^{\sharp_1}]_{F^*}$ for all $\vv \in V$''. Notice that if we show that $\Phi_\vv^{\widetilde{\sharp}_1} = \vv^{\flat_1}$ for all $\vv \in V$, then this equation involves only $\vv$ and not $\Phi_\vv$, and becomes $[\vv]_E = \widetilde{\BB}^\top [\vv^{\flat_1}]_{F^*}$. This condition does hold: we have $(\Phi_\vv^{\widetilde{\sharp}_1} = \vv^{\flat_1} \text{ for all } \vv \in V) \iff (\Phi_\vv = (\vv^{\flat_1})^{\widetilde{\flat}_1} \text{ for all } \vv \in V) \iff ((\vv \mapsto \Phi_\vv) = \widetilde{\flat}_1 \circ \flat_1)$, where this last condition is just the first item of Theorem \ref{ch::bilinear_forms_metric_tensors::thm::B_Btilde_kind_of_inverses}. So we know $[\vv]_E = \widetilde{\BB}^\top [\vv^{\flat_1}]_{F^*}$ for all $\vv \in V$. Use the fact that $\widetilde{\BB} = \BB^{-1}$ from Theorem \ref{ch::bilinear_forms_metric_tensors::thm::B_Btilde_kind_of_inverses} to obtain $([\vv]_E = (\BB^{-1})^\top [\vv^{\flat_1}]_{F^*} = (\BB^{-\top}) [\vv^{\flat_1}]_{F^*} \text{ for all $\vv \in V$}$, as desired.
\end{proof}

\begin{remark}
    (Metric tensors and coordinates of vectors and dual vectors).
    
    When tensors are used in physics, the above theorem is employed to the situation in which we have a vector space $V$ with a metric tensor $g$. (Recall that a metric tensor on $V$ is a nondegenerate symmetric bilinear form on $V$).
    
    Since $g$ is symmetric, we have $\flat := \flat_1 = \flat_2$, $\sharp := \sharp_1 = \sharp_2$, and $\gg^\top = \gg$, so the above equations simplify to 
    
    \begin{align*}
        [\vv]_E = \gg^{-1} [\vv^{\flat}]_{E^*} &\iff [\vv^{\flat}]_{E^*} = \gg [\vv]_E \\
        [\phi]_{E^*} = \gg [\phi^{\sharp}]_E &\iff [\phi^{\sharp}]_E = \gg^{-1} [\phi]_{E^*}.
    \end{align*}
    
    Physicists also make the definitions $v^i := ([\vv]_E)^i$, $v_i := ([\vv^{\flat}]_{E^*})_i$, $\phi_i := ([\phi]_{E^*})_i$, and $\phi^i := ([\phi^{\sharp}]_E)^i$. With these definitions, the above equations become
    
    \begin{align*}
        v^i = \sum_j g^{ij} v_j &\iff v_i = \sum_j g_{ij} v^j \\
        \phi_i = \sum_j g_{ij} \phi^j &\iff \phi^i = \sum_j g^{ij} \phi_j.
    \end{align*}
    
    This notation has the advantage of being compact, and it's what I would personally use when doing calculations. However, it is best for reference materials such as this one to introduce the relations between $v^i$ and $v_i$ with notation that does involve explicit mention of the basis $E$.
\end{remark}

investigate whether below theorem can be discovered without knowing the above thm about $\BB$ and coordinates

[$T_{p,q}(V) \cong T^r_s(V)$ when $p + q = r + s$. Normally this isomorphism is not natural, and we have to obtain it by choosing a basis. But when we have a metric tensor $g$ on $V$, then the musical isomorphism $\flat:V \rightarrow V^*$ achieves this isomorphism naturally.]

\begin{theorem}
    (Using a metric tensor to convert between vectors and dual vectors in a $(p, q)$ tensor).
    
    \textbf{double check whether $B_{ij} = B_{ji}$ is used or not in this theorem. i really hope it isn't...}
    
    \textbf{seems like it's not. we'll just have to change $\flat$ to $\flat_1$ and state two extra results at end to generalize to case when multiplying by $B_{jr}$ rather than $B_{rj}$}
    
    Let $V$ be a finite-dimensional vector space with basis $E = \{\ee_1, ..., \ee_n\}$, and let $B$ be a metric tensor on $V$, with $\flat = \flat_1 = \flat_2$ being the musical isomorphism $V \rightarrow V^*$ (recall Definition \ref{ch::bilinear_forms_metric_tensors::defn::nondegen_bilinear_form}), and let $E^* = \{\phi^{\ee_1}, ..., \phi^{\ee_n}\}$ be the dual basis for $V^*$ induced by $E$. (Note: recall from Remark \ref{ch::bilinear_forms_metric_tensors::thm::musical_iso_unique_self_dual_iso} that $\ee_i \mapsto \phi^{\ee_i}$ is a natural isomorphism, due to the presence of $\flat$).
    
    We can send a basis $(p, q)$ tensor $\TT = \ee_{i_1} \otimes ... \otimes &\ee_{i_k} \otimes ... \otimes \ee_{i_p} \otimes \phi^{\ee_{j_1}} \otimes ... \otimes \phi^{\ee_{j_q}} \in T_{p,q}(V)$ to a $(p - 1, q + 1)$ tensor by applying the map $\flat:V \rightarrow V^*$ to one of the $p$ vectors in $\TT$.
    
    \begin{align*}
        \TT = \ee_{i_1} \otimes ... \otimes &\ee_{i_k} \otimes ... \otimes \ee_{i_p} \otimes \phi^{\ee_{j_1}} \otimes ... \otimes \phi^{\ee_{j_q}} \\
        &\qquad \longmapsto \\
        \ee_{i_1} \otimes ... \otimes &\ee_{i_k}^{\flat} \otimes ... \otimes \ee_{i_p} \otimes \phi^{\ee_{j_1}} \otimes ... \otimes \phi^{\ee_{j_q}}.
    \end{align*}
    
    Using Theorem \ref{ch::bilinear_forms_metric_tensors::coords_vectors_dual_vectors}, we compute $\ee_{i_k}^{\flat}$ to be 
    
    \begin{align*}
        \ee_{i_k}^{\flat} = \sum_{r = 1}^n ([\ee_{i_k}^{\flat}]_{E^*})_r \phi^{\ee_r} \underset{\text{Theorem \ref{ch::bilinear_forms_metric_tensors::coords_vectors_dual_vectors}}}{=}
        \sum_{r = 1}^n \Big( \sum_{j = 1}^n g_{rj} ([\ee_{i_k}]_E)^j \Big) \phi^{\ee_r} = \sum_{r = 1}^n \Big( \sum_{j = 1}^n g_{rj} \delta^j{}_{i_k} \Big) \phi^{\ee_r}
        = \sum_{r = 1}^n g_{i_k r} \phi^{\ee_r},
    \end{align*}
    
    so $\TT$ is sent to
    
    \begin{align*}
        &\ee_{i_1} \otimes ... \otimes \ee_{i_{k - 1}} \otimes \sum_{r = 1}^n \Big( g_{i_k r} \phi^{\ee_r} \Big) \otimes \ee_{i_{k + 1}} \otimes ... \otimes \ee_{i_p} \otimes \phi^{\ee_{j_1}} \otimes ... \otimes \phi^{\ee_{j_q}} \\
        &= \sum_{r = 1}^n g_{i_k r} \Big( \ee_{i_1} \otimes ... \otimes \ee_{i_{k - 1}} \otimes \phi^{\ee_r} \otimes \ee_{i_{k + 1}} \otimes ... \otimes \ee_{i_p} \otimes \phi^{\ee_{j_1}} \otimes ... \otimes \phi^{\ee_{j_q}} \Big).
    \end{align*}
    
    Thus, if the coordinates of $\TT$ relative to $E$ and $E^*$ were originally $T^{i_1 ... i_p}{}_{j_1 ... j_q}$, then they get sent to 
    
    \begin{align*}
        \sum_{r = 1}^n g_{i_k r} T^{i_1 ... i_{k - 1}}{}_{r}{}^{i_{k + 1} ... i_p}{}_{j_1 ... j_q}.
    \end{align*}
    
    Following a similar process to above, we can use the other musical isomorphism, the sharp map $\sharp = \flat^{-1}$, to convert a $(p, q)$ tensor to a $(p + 1, q - 1)$ tensor. This approach would send $T^{i_1 ... i_p}{}_{j_1 ... j_q}$ to
    
    \begin{align*}
        \sum_{r = 1}^n g^{j_k r} T^{i_1 ... i_p}{}_{j_1 ... j_{k - 1}}{}^{r}{}_{j_{k + 1} ... j_q}.
    \end{align*}
    
    So we have the following ``index lowering'' and ``index raising'' mappings:
    
    \begin{empheq}[box = \fbox]{align*}
        T^{i_1 ... i_p}{}_{j_1 ... j_q} &\mapsto \sum_{r = 1}^n g_{i_k r} T^{i_1 ... i_{k - 1}}{}_{r}{}^{i_{k + 1} ... i_p}{}_{j_1 ... j_q} \quad \text{(index lowering)} \\
        T^{i_1 ... i_p}{}_{j_1 ... j_q} &\mapsto \sum_{r = 1}^n g^{j_k r} T^{i_1 ... i_p}{}_{j_1 ... j_{k - 1}}{}^{r}{}_{j_{k + 1} ... j_q} \quad \text{(index raising)}
    \end{empheq}
\end{theorem}

\subsection*{Change of basis for $(p, q)$ tensors}

\begin{theorem}
    (Change of basis for vectors and dual vectors).
    
    Let $V$ be a finite-dimensional vector space with bases $E$ and $F$, and let $E^*$ and $F^*$ be the corresponding induced dual bases for $V^*$. Then
    
    \begin{empheq}[box = \fbox]{align*}
        [\vv]_F &= [\EE]_F [\vv]_E = [\FF]_E^{-1} [\vv]_E \\
        [\phi]_{F^*} &= [\EE]_F^{-\top} [\phi]_{E^*} = [\FF]_E^\top [\phi]_{E^*} \\
        [\EE]_F &= [\EE^*]_{F^*} = [\FF]_E^{-1}
    \end{empheq}
    
    where $\vv \in V$ and $\phi \in V^*$.
\end{theorem}

\begin{proof}
    The first line of the boxed equation is Theorem \ref{ch::lin_alg::thm::change_of_basis_for_vectors}, and the equation $[\EE]_F = [\FF]_E^{-1}$ from the third line is Theorem \ref{ch::lin_alg::thm::I_EF}. 
    
    The equation $[\EE]_F = [\EE^*]_{F^*}$ from the third line is true because  if $\GG:V \rightarrow V^*$ is the isomorphism sending basis vectors to induced dual basis vectors, then we have $[\vv]_E = [\GG(\vv)]_{E^*}$ for any $\vv \in V$ (see Theorem \ref{ch::bilinear_forms_metric_tensors::thm:vv_E_eq_phi_vv_Estar}).
    
    The second line follows by noticing that the first line implies $[\phi]_{F^*} = [\EE^*]_{F^*} [\vv]_{E^*}$, and then applying the equation $[\EE]_F = [\EE^*]_{F^*}$ of the third line.
\end{proof}

\begin{remark}
\label{ch::bilinear_forms_metric_tensors::rmk::covar_contarvar_real_meaning}

    (What ``covariance'' and ``contravariance'' refer to).

    The first two equations of the previous theorem can be restated as
    
    \begin{align*}
        [\vv]_F &= [\FF]_E^{-1} [\vv]_E \\
        [\phi]_{F^*}^\top &= [\phi]_{E^*}^\top [\FF]_E.
    \end{align*}
    
    (We have simply copied the first equation from the previous theorem. The second equation has been obtained by applying the matrix transpose to its counterpart from the previous theorem).
    
    Paying close attention to the second above equation, we see that when we treat the coordinates of dual vectors taken relative to the $E^*$ basis as row vectors (i.e. as transposed column vectors), then these row vectors transform over to the $F^*$ basis with use of $[\FF]_E$. On the other hand, the first equation states that the coordinates of vectors relative to $E$ (when treated as column vectors, as usual) transform over to the $F$ basis with use of $[\FF]_E^{-1}$. Thus, dual vectors ``co-vary'' \textit{with} $[\FF]_E$ when changing basis from $E$ to $E^*$, and vectors ``contra-vary'' \textit{against} $[\FF]_E$ when changing basis from $F$ to $F^*$.
\end{remark}

\begin{theorem}
    (Change of basis for vectors and dual vectors in terms of basis vectors and basis dual vectors).
    
    Let $V$ be a finite-dimensional vector space with bases $E = \{\ee_1, ..., \ee_n\}$ and $F = \{\ff_1, ..., \ff_n\}$, and let $E^* = \{\phi^{\ee_1}, ..., \phi^{\ee_n}\}$ and $F^* = \{\psi^{\ff_1}, ..., \psi^{\ff_n} \}$ be the corresponding induced dual bases for $V^*$. We have
    
    \begin{empheq}[box = \fbox]{align*}
        \ff_i &= \sum_{j = 1}^n ([\ff_i]_E)_j \ee_j = \sum_{j = 1}^n ([\FF]_E)^j_i \ee_j \\
        \psi^{\ff_i} &= \sum_{j = 1}^n ([\psi^{\ff_i}]_{E^*})_j \phi^{\ee_j} = \sum_{j = 1}^n ([\FF]_E^{-\top})^j_i \phi^{\ee_j}
    \end{empheq}
\end{theorem}

\begin{proof}
    The first line in the boxed equation follows directly from the definition of $[\cdot]_F$. (The first line is also Theorem \ref{ch::lin_alg::thm::change_of_basis_with_basis_vectors})). The second line in the boxed equation follows by applying the first line to the bases $F^*$ and $E^*$ for $V^*$. Specifically, the second equation in the second line follows because $\psi^{\ff_i} = \sum_{j = 1}^n ([\FF^*]_{E^*})^j_i \phi^{\ee_j}$, where we have $[\FF^*]_{E^*} = [\FF]_E^{-\top}$ due to the previous theorem.
\end{proof}

\begin{theorem}
\label{ch::bilinear_forms_metric_tensors::thm::ricci}

    (Change of basis for a $(p, q)$ tensor). 
    
    Let $V$ be a finite-dimensional vector space with bases $E = \{\ee_1, ..., \ee_n\}$ and $F = \{\ff_1, ..., \ff_n\}$, and let $E^* = \{\phi^{\ee_1}, ..., \phi^{\ee_n}\}$ and $F^* = \{\psi^{\ff_1}, ..., \psi^{\ff_n}\}$ be the corresponding induced dual bases for $V^*$.
    
    We now derive how to change the coordinates of a $(p, q)$ tensor in $T_{p,q}(V)$. To do so, it is enough to relate the coordinates relative to $F$ and $F^*$ of the $(p, q)$ tensor

    \begin{align*}
       \TT = \sum_{\substack{i_1, ..., i_p \in \{1, ..., n\} \\ j_1, ..., j_q \in \{1, ..., n\}}}
       T^{i_1 ... i_p}{}_{j_1 ... j_q} \ff_{i_1} \otimes ... \otimes \ff_{i_p} \otimes \psi^{\ff_{j_1}} \otimes ... \otimes \psi^{\ff_{j_q}}
    \end{align*}
    
    to the coordinates of $\TT$ relative to $E$ and $E^*$.
    
    To obtain this relation, we apply the previous theorem to each basis vector in $\TT$.
    
    \begin{align*}
        &\ff_{i_1} \otimes ... \otimes \ff_{i_p} \otimes \psi^{\ff_{j_1}} \otimes ... \otimes \psi^{\ff_{j_q}} \\
        &= \Big(\sum_{j_1 = 1}^n ([\FF]_E)^{j_1}_{i_1} \ee_{j_1} \Big) \otimes ... \otimes \Big(\sum_{j_p = 1}^n ([\FF]_E)^{j_p}_{i_p} \ee_{j_p} \Big)
        \otimes
        \Big( \sum_{i_1 = 1}^n ([\FF_E]^{-1})^{j_1}_{i_1} \phi^{\ee_{i_1}} \Big) \otimes
        ... \otimes \Big( \sum_{i_q = 1}^n ([\FF_E]^{-1})^{j_q}_{i_q} \phi^{\ee_{i_q}} \Big) \\
        &= \sum_{j_1 = 1}^n ... \sum_{j_p}^n \sum_{i_1 = 1}^n ... \sum_{i_q = 1}^n \Big( ([\FF]_E)^{j_1}_{i_1} ... ([\FF]_E)^{j_p}_{i_p}
        ([\FF_E]^{-1})^{j_1}_{i_1} ... ([\FF_E]^{-1})^{j_q}_{i_q} 
        \ee_{j_1} \otimes ... \otimes \ee_{j_p} \otimes \phi^{\ee_{i_1}} \otimes ... \otimes \phi^{\ee_{i_q}} \Big).
    \end{align*}
    
    After substituting this expression back into the basis sum for $\TT$, we see that an arbitrary $(p, q)$ tensor with an $\Big( {}^{i_1 ... i_p}{}_{j_1 ... j_q} \Big)$ component of $T^{i_1 ... i_p}{}_{j_1 ... j_q}$ relative to $F$ and $F^*$ has a $\Big( {}^{i_1 ... i_p}{}_{j_1 ... j_q} \Big)$ component relative to $E$ and $E^*$ of 
    
    \begin{align*}
        &\sum_{k_1 = 1}^n ... \sum_{k_p}^n \sum_{\ell_1 = 1}^n ... \sum_{\ell_q = 1}^n \Big( ([\FF]_E)^{k_1}_{\ell_1} ... ([\FF]_E)^{k_p}_{\ell_p}
        ([\FF_E]^{-1})^{k_1}_{\ell_1} ... ([\FF_E]^{-1})^{k_q}_{\ell_q} 
        T^{k_1 ... k_p}_{\ell_1 ... \ell_q}\Big).
    \end{align*}
    
    (It is possible to ``simplify'' this expression by using the fact that $([\FF]_E)^i_j ([\FF]_E)^{-1})^i_j = \delta^i{}_j$. Let's not do that, because that would require introducing the $\max$ function to account for whether $p \geq q$ or $q < p$).
    
    This change of basis formula is sometimes called the \textit{Ricci transformation law}, or the \textit{tensor transformation law}.
    
    At this stage, it would be remiss not to mention what is called \textit{Einstein summation notation}. In Einstein summation notation, we assume that there is an ``implied summation'' over any index that appears in both a lower and upper index. We can use Einstein notation to write the $\Big( {}^{i_1 ... i_p}{}_{j_1 ... j_q} \Big)$ component of $\TT$ relative to $E$ and $E^*$ as
    
    \begin{align*}
        ([\FF]_E)^{k_1}_{\ell_1} ... ([\FF]_E)^{k_p}_{\ell_p}
        ([\FF_E]^{-1})^{k_1}_{\ell_1} ... ([\FF_E]^{-1})^{k_q}_{\ell_q} 
        T^{k_1 ... k_p}_{\ell_1 ... \ell_q} \quad \text{(Einstein notation)}.
    \end{align*}
\end{theorem}

\begin{remark}
    (Tensors as ``multidimensional matrices'' that ``transform like tensors''). 
    
    As was mentioned in Remark \ref{ch::motivated_intro::rmk::many_defs_tensor}, physicists often define tensors to be ``multidimensional matrices'' that follow the change of basis formula of the previous theorem.
\end{remark}

\subsection*{Tensor contraction}

\begin{deriv}
\label{ch::bilinear_forms_metric_tensors::deriv::compos_linear_map_with_contract}
    (Composition of linear functions with contraction). 
    
    Let $V, W$ and $Z$ be vector spaces over a field $K$. Notice that the map $\circ$ which composes linear a function $V \rightarrow W$ with a linear function $W \rightarrow Z$ is itself a bilinear map $\LLLL(V \rightarrow W) \times \LLLL(W \rightarrow Z) \overset{\circ}{\rightarrow} \LLLL(V, Z)$. (Check this as an exercise!). Also recall from Section \ref{ch::motivated_intro::sec::motivated_intro} that every element of $\LLLL(V \rightarrow W)$ and $\LLLL(W \rightarrow Z)$ is a linear combination of rank-1 compositions of linear functions, i.e., of ``elementary compositions''. Thus, we can understand the composition map $\circ$ more deeply by looking at how it acts on such elementary compositions. 
    
    Lastly, recall the convention of Section \ref{ch::motivated_intro::sec::motivated_intro} which, for $\ww \in W$, uses the same symbol $\ww$ to denote the linear map $\ww \in \LLLL(K \rightarrow W)$ defined by $\ww(c) = c\ww$. Then, under the composition map, ${(\zz \circ \phi, \ww \circ \phi) \in \LLLL(V \rightarrow W) \times \LLLL(W \rightarrow Z)}$ is sent to
    
    \begin{align*}
        (\ww \circ \phi, \zz \circ \psi) \overset{\circ}{\longrightarrow} (\zz \circ \psi) \circ (\ww \circ \phi) = \zz \circ (\psi \circ \ww) \circ \phi.
    \end{align*}
    
    Now, notice that $\phi \circ \ww$ is the linear map $K \rightarrow K$ sending $c \mapsto c\psi(\ww)$. If we extend the above notation (that uses $\ww$ and $\zz$ to denote linear maps) to elements of $K$, and denote the linear map $K \rightarrow K$ sending $c \mapsto c\psi(\ww)$ by $\psi(\ww)$, then we have 
    \begin{align*}
        (\ww \circ \phi, \zz \circ \psi) \overset{\circ}{\longrightarrow} \zz \circ \psi(\ww) \circ \phi = \psi(\ww) \circ \zz \circ \phi = \zz \circ \phi \circ \psi(\ww)
    \end{align*}
    
    (In the last three equalities, we were able to commute $\psi(\ww)$ because it is a linear map $K \rightarrow K$).
    
    In general, the action of $\psi \in W^*$ on $\ww \in W$ is said to be the result of evaluating the \textit{natural pairing map on $W$ and $W^*$}, or, equivalently, the result of \textit{contracting $W$ against $W^*$}. Therefore, we see that the composition of linear maps, when we restrict the linear maps to be elementary compositions, involves \textit{contraction}. These notions are formalized in the next definition.
\end{deriv}

\begin{defn}
\label{ch::bilinear_forms_metric_tensors::defn::tensor_contraction}
    (Tensor contraction).
    
    Let $V$ be a vector space, and consider also its dual space $V^*$. There is a natural bilinear form $C$ on $V$ and $V^*$, often called the \textit{natural pairing (of $V$ and $V^*$)}, that is defined by $C(\vv, \phi) = \phi(\vv)$.
    
    In a slight generalization of the natural pairing map, we define the \textit{$(k, \ell)$ contraction} on elementary $(p, q)$ tensors, and extend with multilinearity. The $(k, \ell)$ contraction of an elementary tensor is defined as follows:

    \begin{align*}
        \vv_1 \otimes ... \otimes &\vv_p \otimes \phi^1 \otimes ... \otimes \phi^q \\
        \overset{\text{$(k, \ell)$ contraction}}&{\longmapsto} \\
        C(\vv_k, \phi^\ell) (\vv_1 \otimes ... \otimes \cancel{\vv_k} &\otimes ... \vv_p \otimes \phi^1 \otimes ... \otimes \cancel{\phi^\ell} \otimes ... \otimes \phi^q) \\
        &= \\
        \phi^\ell(\vv_k) (\vv_1 \otimes ... \otimes \cancel{\vv_k} &\otimes ... \vv_p \otimes \phi^1 \otimes ... \otimes \cancel{\phi^\ell} \otimes ... \otimes \phi^q).
    \end{align*}
\end{defn}

\begin{remark}
    (Contraction with upper and lower indices).
    
    Vectors can only ever get contracted against dual vectors, and dual vectors can only ever get contracted against vectors. Vectors cannot get contracted against vectors, and dual vectors cannot get contracted against dual vectors.
    
    Since the convention we laid out in \ref{ch::motivated_intro::defn::covariance_contravariance} requires that lower indices (e.g. those which appear in $\vv_k$) be used on vectors and that upper indices (e.g. those which appear in $\phi^\ell$) be used on vectors, then it follows that lower indices can only be contracted against upper indices, and that upper indices can only be contracted against lower indices.
\end{remark}

\begin{remark}
    (Composition of linear functions with tensor contraction, revisited). 
    
    The map $\circ$ which composes linear functions is itself a bilinear map ${\LLLL(V \rightarrow W) \times \LLLL(W \rightarrow Z) \overset{\circ}{\rightarrow} \LLLL(V, Z)}$. Due to Theorem \ref{ch::motivated_intro::thm::four_fundamental_isos}, we have the natural isomorphism $\LLLL(V \rightarrow W) \cong W \otimes V^*$, so $\circ$ can be identified with a linear map $\widetilde{\circ}:(W \otimes V^*) \otimes (Z^* \otimes W) \rightarrow Z \otimes V^*$. Following a similar argument as was presented in Derivaton \ref{ch::bilinear_forms_metric_tensors::deriv::compos_linear_map_with_contract}, we see that $\widetilde{\circ}$ acts on elementary tensors by $(\ww \otimes \phi) \otimes (\zz \circ \psi) \overset{\widetilde{\circ}}{\mapsto} C(\ww, \psi) (\zz \otimes \phi) = \psi(\ww) (\zz \otimes \phi)$.
\end{remark}

\begin{theorem}
    (Coordinates of a contracted tensor).

    Let $V$ be an $n$-dimensional vector space, let $E$ be a basis for $V$, let $g$ be a metric tensor on $V$, and let $E^*$ be the induced dual basis for $V^*$. Consider a $(p, q)$ tensor $\TT \in T_{p,q}(V)$. If the $\Big( {}^{i_1 ... i_p}{}_{j_1 ... j_q} \Big)$ coordinate of $\TT$ relative to $E$ and $E^*$ is $T^{i_1 ... i_p}{}_{j_1 ... j_q}$, then the $\Big( ^{i_1 ... i_{p - 1}}{}_{j_1 ... j_{q - 1}} \Big)$ component of the $(k, \ell)$ contraction of $\TT$ relative to $E$ and $E^*$ is \textbf{come back here} $\sum_{r = 1}^n T^{i_1 ... i_{k - 1} \spc r \spc i_k ... i_{p - 1}}{}_{j_1 ... j_{\ell - 1} \spc r \spc j_{\ell} ... j_{q - 1}}$.
\end{theorem}

\begin{proof}
     Let $E = \{\ee_1, ..., \ee_n\}$ and $E^* = \{\phi^{\ee_1}, ..., \phi^{\ee_n}\}$. Assume $\TT$ has a $\Big( {}^{i_1 ... i_p}{}_{j_1 ... j_q} \Big)$ component of $T^{i_1 ... i_p}{}_{j_1 ... j_q}$ relative to $E$ and $E^*$, so
     
    \begin{align*}
        \TT = \sum_{\substack{i_1 ..., i_p \in \{1, ..., n\} \\ j_1, ..., j_q \in \{1, ..., n\}}} T^{i_1 ... i_p}{}_{j_1 ... j_q} \ee_{i_1} \otimes ... \otimes \ee_{i_p} \otimes \epsilon^{j_1} \otimes ... \otimes \epsilon^{j_q}.
    \end{align*}
     
    Using that $\phi^{\ee_{j_\ell}}(\ee_{i_k}) = \ee_{j_\ell}^\flat(\ee_{i_k}) = g(\ee_{j_\ell}, \ee_{i_k}) = g_{j_\ell i_k} = g_{i_k j_\ell}$, we see that the $(k, \ell)$ contraction of $\TT$ is
    
    \begin{align*}
        &\sum_{\substack{i_1 ..., i_p \in \{1, ..., n\} \\ j_1, ..., j_q \in \{1, ..., n\}}} \phi^{\ee_{j_\ell}}(\ee_{i_k}) \spc T^{i_1 ... i_p}{}_{j_1 ... j_q} \ee_{i_1} \otimes ... \otimes \cancel{\ee_{i_k}} \otimes ... \otimes \ee_{i_p} \otimes \epsilon^{j_1} \otimes ... \otimes \cancel{\epsilon^{j_\ell}} \otimes... \otimes \epsilon^{j_q} 
        \\
        = &\sum_{\substack{i_1 ..., i_p \in \{1, ..., n\} \\ j_1, ..., j_q \in \{1, ..., n\}}} g_{i_k j_\ell} \spc T^{i_1 ... i_p}{}_{j_1 ... j_q} \ee_{i_1} \otimes ... \otimes \cancel{\ee_{i_k}} \otimes ... \otimes \ee_{i_p} \otimes \epsilon^{j_1} \otimes ... \otimes \cancel{\epsilon^{j_\ell}} \otimes... \otimes \epsilon^{j_q} 
        \\
        &= \sum_{i_k, j_\ell \in \{1, ..., n\}} g_{i_k j_\ell} \sum_{\substack{i_1 ..., \cancel{i_k}, ..., i_p \in \{1, ..., n\} \\ j_1, ..., \cancel{j_\ell}, ..., j_q \in \{1, ..., n\}}} T^{i_1 ... i_p}{}_{j_1 ... j_q} \ee_{i_1} \otimes ... \otimes \cancel{\ee_{i_k}} \otimes ... \otimes \ee_{i_p} \otimes \epsilon^{j_1} \otimes ... \otimes \cancel{\epsilon^{j_\ell}} \otimes... \otimes \epsilon^{j_q} 
        \\
        &= \sum_{i_k, j_\ell \in \{1, ..., n\}} g_{i_k j_\ell} \sum_{\substack{i_1 ..., \cancel{i_k}, ..., i_p \in \{1, ..., n\} \\ j_1, ..., \cancel{j_\ell}, ..., j_q \in \{1, ..., n\} \\ r \in \{1, ..., n\}}} T^{i_1 ... i_{k - 1} \spc r \spc i_{k + 1} ... i_p}{}_{j_1 ... j_{\ell - 1} \spc r \spc j_{\ell + 1} ... j_q} \ee_{i_1} \otimes ... \otimes \cancel{\ee_{i_k}} \otimes ... \otimes \ee_{i_p} \otimes \epsilon^{j_1} \otimes ... \otimes \cancel{\epsilon^{j_\ell}} \otimes... \otimes \epsilon^{j_q} 
    \end{align*}
        
    So, we can see that
    
    \begin{align*}
        \text{The $\Big( {}^{i_1 ... \cancel{i_k} ... i_p}{}_{j_1 ... \cancel{j_\ell} ... j_p} \Big)$ component of the $(k, \ell)$ contraction of $\TT$ is } \sum_{i_k, j_\ell} g_{i_k j_\ell} \sum_r T^{i_1 ... i_{k - 1} \spc r \spc i_{k + 1} ... i_p}{}_{j_1 ... j_{\ell - 1} \spc r \spc j_{\ell + 1} ... j_q}.
    \end{align*}

    Equivalently, after shifting the indices $i_{k + 1}, ..., i_p$ down by one (this is valid because the indices $i_k$ and $j_\ell$ are no longer ``occupied''), we see
        
    \begin{align*}
        \text{The $\Big( {}^{i_1 ... i_{p - 1}} {}_{j_1 ... j_{q - 1}} \Big)$ component of the $(k, \ell)$ contraction of $\TT$ is } \sum_{i_k, j_\ell} g_{i_k j_\ell} \sum_r T^{i_1 ... i_{k - 1} \spc r \spc i_k ... i_{p - 1}}{}_{j_1 ... j_{\ell - 1} \spc r \spc j_{\ell} ... j_{q - 1}}.
    \end{align*}
    
    Additionally, when $E$ is an orthonormal basis, we have $g_{i_k j_\ell} = \delta_{i_k j_\ell}$ and thus
    
    \begin{align*}
        \text{The $\Big( {}^{i_1 ... i_{p - 1}} {}_{j_1 ... j_{q - 1}} \Big)$ component of the $(k, \ell)$ contraction of $\TT$ is } \sum_r T^{i_1 ... i_{k - 1} \spc r \spc i_k ... i_{p - 1}}{}_{j_1 ... j_{\ell - 1} \spc r \spc j_{\ell} ... j_{q - 1}} \\ \text{when the basis for $V$ is orthonormal}.
    \end{align*}
    
    In Einstein notation, this is stated as
    
    \begin{align*}
        \text{The $\Big( {}^{i_1 ... i_{p - 1}} {}_{j_1 ... j_{q - 1}} \Big)$ component of the $(k, \ell)$ contraction of $\TT$ is } T^{i_1 ... i_{k - 1} \spc r \spc i_k ... i_{p - 1}}{}_{j_1 ... j_{\ell - 1} \spc r \spc j_{\ell} ... j_{q - 1}} \\ \text{when the basis for $V$ is orthonormal}.
    \end{align*}
\end{proof}

\begin{theorem}
    Taking any $(k, \ell)$ contraction is basis-independent.
\end{theorem}

\begin{proof}
    Recall that the definition of tensor contraction was phrased entirely in terms of tensor products of vectors and dual vectors; no bases were involved.
\end{proof}

\begin{theorem}
    (The trace is the $(1, 1)$ contraction of a $(1, 1)$ tensor).
    
    Let $V$ be a finite-dimensional vector space over a field $K$.
    
    The \textit{trace} of a square matrix $(a^i{}_j)$ with entries in $K$ is defined to be the sum of the matrix's diagonal entries: $\tr(a^i{}_j) := \sum_{i = 1}^n a^i_i$. We have that $\tr(a^i{}_j)$ is the $(1, 1)$ contraction of the $(1, 1)$ tensor corresponding to $(a^i{}_j)$.
    
    Thus, we see the trace is a special case of tensor contraction.
\end{theorem}

\begin{proof}
    Let $\ff:K^n \rightarrow K^n$ be the linear function satisfying $[\ff(\sE)]_\sE = (a^i{}_j)$, where $\sE = \{\see_1, ..., \see_n\}$ is the standard basis for $K^n$. Recall from Theorem \ref{ch::motivated_intro::thm::lin_V_W_iso_W_otimes_V} that if $V$ is a vector space, then there is a natural isomorphism $\LLLL(V \rightarrow V) \cong V \otimes V^*$. Using $V = K^n$, we see that $(a^i{}_j)$ can be identified with the $(1, 1)$ tensor $\sum_{ij} a^i{}_j \see^i \otimes \phi^{\see_j}$, where $E^* = \{\phi^{\see_1}, ..., \phi^{\see_n}\}$ is the basis for $(K^n)^*$ induced by the standard basis $\sE = \{\see_1, ..., \see_n\}$ for $K^n$. The $(1, 1)$ contraction of this $(1, 1)$ tensor is $\sum_{ij} a^i{}_j \phi^{\see_j}(\see^i) = \sum_{ij} a^i{}_j \delta^i{}_j = \sum_i a^i_i = \tr(a^i{}_j)$. 
\end{proof}